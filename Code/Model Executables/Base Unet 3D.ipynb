{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Base Unet 3D GPU.ipynb","provenance":[{"file_id":"15OGGwfZ-L-b7GpGfh8ivzObTo10-ehAl","timestamp":1595948230246},{"file_id":"1WNe9cvMG-tFuuPtd2VZwd6paZIdG-WfT","timestamp":1595927266342}],"collapsed_sections":["De-sVZQJYsdh","Jwyn3cHR2l7x","8ZZydFrv7rVq","9Ud879-cD8_x"],"authorship_tag":"ABX9TyMtZPqI8ACdYZcNY+r/6PcL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JEgNgZ_YMIhS","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import gzip, shutil\n","import nibabel as nib\n","import time\n","import random\n","\n","import torch\n","from torch.utils.data import Dataset\n","\n","import torch.nn.functional as F\n","from torch import nn as nn\n","from torch.autograd import Variable\n","from torch.nn import MSELoss, SmoothL1Loss, L1Loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BeGFN-cO87Jn","colab_type":"code","colab":{}},"source":["nobackup = '/nobackup/sc19rw/Train/'\n","nobackup_models = '/nobackup/sc19rw/Models/'\n","home = '/home/home01/sc19rw/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M03a0Rx_G8qk","colab_type":"text"},"source":["## Data collection"]},{"cell_type":"code","metadata":{"id":"fwkeVBofs49S","colab_type":"code","colab":{}},"source":["def get_random_crop(img,cropx,cropy,cropz):\n","    x,y,z = img.shape\n","    startx = random.randint(0,(x-cropx))\n","    starty = random.randint(0,(y-cropy))\n","    startz = random.randint(0,(z-cropz))\n","    return startx, starty, startz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBLl5JlQwCVE","colab_type":"code","colab":{}},"source":["MRI_ids = np.load(home+\"MRI_ids.npz\") #make sure you use the .npz!\n","MRI_ids = MRI_ids['arr_0']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-iIj__UImW2I","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import random\n","\n","\n","root = nobackup\n","\n","data = {\n","    'image_id': MRI_ids,\n","    't1_path': [root + MRI_id + \"_t1_norm\"+ \".nii\" for MRI_id in MRI_ids],\n","    't1ce_path': [root + MRI_id + \"_t1ce_norm\" + \".nii\" for MRI_id in MRI_ids],\n","    'flair_path': [root + MRI_id + \"_flair_norm\" + \".nii\" for MRI_id in MRI_ids],\n","    't2_path': [root + MRI_id + \"_t2_norm\" + \".nii\" for MRI_id in MRI_ids],\n","    'seg_path': [root + MRI_id + \"_seg\" + \".nii\" for MRI_id in MRI_ids],\n","}\n","\n","data_df = pd.DataFrame(data, columns=['image_id', 't1_path', 't1ce_path', 'flair_path', 't2_path', 'seg_path'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePs10Qr_pAEC","colab_type":"code","colab":{}},"source":["class BRATS_DATA_CROPPED(Dataset):\n","    \"\"\" BRATS custom dataset compatible with torch.utils.data.DataLoader. \"\"\"\n","    \n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","\n","        MRI_id = self.df['image_id'][index] \n","        t1_path = self.df['t1_path'][index]\n","        t1ce_path = self.df['t1ce_path'][index]\n","        flair_path = self.df['flair_path'][index]\n","        t2_path = self.df['t2_path'][index]\n","        seg_path = self.df['seg_path'][index]\n","\n","        seg_map = nib.load(seg_path)\n","        affine = seg_map.affine\n","\n","        seg_map = seg_map.get_fdata()\n","\n","        cropx,cropy,cropz = 128, 128, 128\n","        startx,starty,startz = get_random_crop(seg_map, cropx,cropy,cropz)\n","\n","        t1_MRI = nib.load(t1_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        t1ce_MRI = nib.load(t1ce_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        flair_MRI = nib.load(flair_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        t2_MRI = nib.load(t2_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        seg_map = seg_map[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","\n","        \n","        input_tensor = np.concatenate((t1_MRI, t1ce_MRI, flair_MRI, t2_MRI), axis=0) \n","     \n","\n","        return input_tensor, seg_map, affine, MRI_id\n","\n","    def __len__(self):\n","        return len(self.df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3EPRK3gbtG0i","colab_type":"code","colab":{}},"source":["class BRATS_DATA(Dataset):\n","    \"\"\" BRATS custom dataset compatible with torch.utils.data.DataLoader. \"\"\"\n","    \n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","\n","        MRI_id = self.df['image_id'][index] \n","        t1_path = self.df['t1_path'][index]\n","        t1ce_path = self.df['t1ce_path'][index]\n","        flair_path = self.df['flair_path'][index]\n","        t2_path = self.df['t2_path'][index]\n","        seg_path = self.df['seg_path'][index]\n","\n","        seg_map = nib.load(seg_path)\n","        affine = seg_map.affine\n","\n","        t1_MRI = nib.load(t1_path).get_fdata()[:].reshape(1,240,240,155)\n","        t1ce_MRI = nib.load(t1ce_path).get_fdata()[:].reshape(1,240,240,155)\n","        flair_MRI = nib.load(flair_path).get_fdata()[:].reshape(1,240,240,155)\n","        t2_MRI = nib.load(t2_path).get_fdata()[:].reshape(1,240,240,155)\n","        seg_map = seg_map.get_fdata()[:].reshape(1,240,240,155)\n","\n","        \n","        input_tensor = np.concatenate((t1_MRI, t1ce_MRI, flair_MRI, t2_MRI), axis=0) \n","     \n","\n","        return input_tensor, seg_map, affine, MRI_id\n","\n","    def __len__(self):\n","        return len(self.df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvd4iZdXxFJq","colab_type":"code","colab":{}},"source":["train_split = 0.8 # Defines the ratio of train/test data.\n","\n","train_size = round(len(data_df)*train_split)\n","test_size = round(len(data_df)*(1-train_split))\n","\n","dataset_train = BRATS_DATA_CROPPED(\n","    df=data_df[:train_size].reset_index(drop=True),\n",")\n","\n","dataset_test = BRATS_DATA_CROPPED(\n","    df=data_df[-test_size:].reset_index(drop=True),\n",")\n","\n","dataset_total = BRATS_DATA( #used to get the final segmentations\n","    df=data_df[:len(data_df)].reset_index(drop=True),\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"De-sVZQJYsdh","colab_type":"text"},"source":["##Data Augmentation"]},{"cell_type":"code","metadata":{"id":"ObGhn7nyAjyH","colab_type":"code","colab":{}},"source":["from batchgenerators.dataloading.data_loader import DataLoaderBase\n","from batchgenerators.transforms.abstract_transforms import Compose\n","from batchgenerators.dataloading.single_threaded_augmenter import SingleThreadedAugmenter\n","from batchgenerators.transforms.spatial_transforms import SpatialTransform_2\n","from batchgenerators.transforms.spatial_transforms import SpatialTransform\n","from batchgenerators.transforms.spatial_transforms import MirrorTransform\n","from batchgenerators.transforms.color_transforms import GammaTransform"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L6JRNV1GSjxf","colab_type":"code","colab":{}},"source":["class DataLoader(DataLoaderBase): #SlimDataLoaderBase \n","    def __init__(self, data, BATCH_SIZE=1, num_batches=None, seed=False):\n","        super(DataLoader, self).__init__(data, BATCH_SIZE, num_batches, seed) \n","        # data is now stored in self._data.\n","        self.index = 0\n","        self.batch_size = BATCH_SIZE\n","    \n","    def generate_train_batch(self):\n","        currentindex = self.index\n","        self.index += 1\n","        if self.index % len(self._data)  == 0:\n","          self.index = 0\n","\n","        data = self._data[self.index][0].reshape(self.batch_size, 4, 128, 128, 128)   #.numpy()\n","        seg = self._data[self.index][1].reshape(self.batch_size, 1, 128, 128, 128)\n","\n","        return {'data':data, 'seg':seg, 'affine':self._data[self.index][2], 'MRI_ID':self._data[self.index][3]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxf_Q4AZT1BT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"status":"ok","timestamp":1595928797000,"user_tz":-120,"elapsed":10198,"user":{"displayName":"Robin W","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1oQMkhoLuxB7sheDY7dP0v-uCx_Q9NOcBrD4=s64","userId":"07744434914462160854"}},"outputId":"14e66aa9-831c-4e74-9757-6f362be7bab2"},"source":["batchgen = DataLoader(dataset_train, 1, len(dataset_train), False) #Basic data loader without augmentation"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/batchgenerators/dataloading/data_loader.py:53: DeprecationWarning: This DataLoader will soon be removed. Migrate everything to SlimDataLoaderBase now!\n","  warn(\"This DataLoader will soon be removed. Migrate everything to SlimDataLoaderBase now!\", DeprecationWarning)\n","/usr/local/lib/python3.6/dist-packages/batchgenerators/dataloading/data_loader.py:58: UserWarning: We currently strongly discourage using num_batches != None! That does not seem to work properly\n","  warn(\"We currently strongly discourage using num_batches != None! That does not seem to work properly\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"SoBE6d2mjGtK","colab_type":"code","colab":{}},"source":["my_transforms = [] #define all augmentation techniques to be applied\n","\n","spatial_transform = SpatialTransform(\n","            dataset_train[0][0][0].shape, dataset_train[0][0][0].shape,\n","            do_elastic_deform=True,\n","            alpha=(0., 175.), sigma=(10., 13.),       \n","            do_rotation=True,\n","            angle_x=(- 5 / 360. * 2 * np.pi, 5 / 360. * 2 * np.pi),\n","            angle_y=(- 5 / 360. * 2 * np.pi, 5 / 360. * 2 * np.pi),\n","            angle_z=(- 5 / 360. * 2 * np.pi, 5 / 360. * 2 * np.pi),\n","            do_scale=True, scale=(0.9, 1.02),\n","            border_mode_data='constant', border_cval_data=0,\n","            border_mode_seg='constant', border_cval_seg=0,\n","            order_seg=1, order_data=3,\n","            random_crop=False,\n","            p_el_per_sample=0.1, p_rot_per_sample=0.1, p_scale_per_sample=0.1)\n","\n","\n","my_transforms.append(spatial_transform)\n","my_transforms.append(MirrorTransform(axes=(0, 1, 2)))\n","my_transforms.append(GammaTransform(gamma_range=(0.7, 1.), invert_image=False, per_channel=True, p_per_sample=0.1))\n","\n","all_transforms = Compose(my_transforms)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoFp9_AFhizK","colab_type":"code","colab":{}},"source":["train_loader = SingleThreadedAugmenter(batchgen, all_transforms) #data loader for training, applying on the fly transformation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"70xp8dPKyBfT","colab_type":"code","colab":{}},"source":["# add other data loaders\n","test_loader = torch.utils.data.DataLoader(\n","    dataset_test,\n","    batch_size=1, \n","    shuffle=False,\n","    num_workers=0,\n",")\n","\n","full_loader = torch.utils.data.DataLoader(\n","    dataset_total,\n","    batch_size=1, \n","    shuffle=False,\n","    num_workers=0,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jwyn3cHR2l7x","colab_type":"text"},"source":["## Building Model \n","\n"]},{"cell_type":"code","metadata":{"id":"5W-2KtVyL9-Q","colab_type":"code","colab":{}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class UNet(nn.Module):\n","    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n","                    torch.nn.LeakyReLU(), \n","                    torch.nn.InstanceNorm3d(out_channels), \n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm3d(out_channels),\n","                )\n","        return block\n","    \n","    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","            block = torch.nn.Sequential(\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm3d(mid_channel),\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm3d(mid_channel),\n","                    torch.nn.ConvTranspose3d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n","                    )\n","            return  block\n","    \n","    def bottleneck_block(self):\n","           block = torch.nn.Sequential(   #put this properly before\n","                            torch.nn.Conv3d(kernel_size=3, in_channels=120, out_channels=240, padding=1),\n","                            torch.nn.LeakyReLU(),\n","                            torch.nn.InstanceNorm3d(240),\n","                            torch.nn.Conv3d(kernel_size=3, in_channels=240, out_channels=120, padding=1),\n","                            torch.nn.LeakyReLU(),\n","                            torch.nn.InstanceNorm3d(120),\n","                            torch.nn.ConvTranspose3d(in_channels=120, out_channels=120, kernel_size=3, stride=2, padding=1, output_padding=1)\n","                            )\n","           return block\n","\n","    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","            block = torch.nn.Sequential(\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm3d(mid_channel),\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm3d(mid_channel),\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n","                    #torch.nn.LeakyReLU(),\n","                    torch.nn.Sigmoid(),\n","                    )\n","            return  block\n","    \n","    def __init__(self):\n","        super(UNet, self).__init__()       \n","        #Encode\n","        self.conv_encode1 = self.contracting_block(in_channels=4, out_channels=15)\n","        self.conv_maxpool1 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode2 = self.contracting_block(15, 30)\n","        self.conv_maxpool2 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode3 = self.contracting_block(30, 60)\n","        self.conv_maxpool3 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode4 = self.contracting_block(60, 120)\n","        self.conv_maxpool4 = torch.nn.MaxPool3d(kernel_size=2)\n","        # Bottleneck\n","        self.bottleneck = self.bottleneck_block()\n","        # Decode\n","        self.conv_decode4 = self.expansive_block(240, 120, 60)\n","        self.conv_decode3 = self.expansive_block(120, 60, 30)\n","        self.conv_decode2 = self.expansive_block(60, 30, 15)\n","        self.final_layer = self.final_block(30, 15, 1)\n","        \n","    \n","    def forward(self, input_tensor):\n","        # Encode\n","        encode_block1 = self.conv_encode1(input_tensor)\n","        encode_pool1 = self.conv_maxpool1(encode_block1)\n","        encode_block2 = self.conv_encode2(encode_pool1)\n","        encode_pool2 = self.conv_maxpool2(encode_block2)\n","        encode_block3 = self.conv_encode3(encode_pool2)\n","        encode_pool3 = self.conv_maxpool3(encode_block3)\n","        encode_block4 = self.conv_encode4(encode_pool3)\n","        encode_pool4 = self.conv_maxpool4(encode_block4)\n","        # Bottleneck\n","        bottleneck1 = self.bottleneck(encode_pool4)\n","        # Decode\n","        if bottleneck1.size()[4] != encode_block4.size()[4]:\n","            bottleneck1 = F.pad(bottleneck1, pad=(1, 0), mode='constant', value=0)\n","        decode_block4 = self.conv_decode4(torch.cat((bottleneck1, encode_block4), 1))\n","        \n","        if decode_block4.size()[4] != encode_block3.size()[4]:\n","            decode_block4 = F.pad(decode_block4, pad=(1, 0), mode='constant', value=0)\n","        decode_block3 = self.conv_decode3(torch.cat((decode_block4, encode_block3), 1))\n","        \n","        if decode_block3.size()[4] != encode_block2.size()[4]:\n","            decode_block3 = F.pad(decode_block3, pad=(1, 0), mode='constant', value=0)\n","        decode_block2 = self.conv_decode2(torch.cat((decode_block3, encode_block2), 1))\n","        \n","        if decode_block2.size()[4] != encode_block1.size()[4]:\n","            decode_block2 = F.pad(decode_block2, pad=(1, 0), mode='constant', value=0)\n","        final_layer = self.final_layer(torch.cat((decode_block2, encode_block1), 1))\n","        return  final_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JXGRiG_tJIco","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1595928800884,"user_tz":-120,"elapsed":14063,"user":{"displayName":"Robin W","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1oQMkhoLuxB7sheDY7dP0v-uCx_Q9NOcBrD4=s64","userId":"07744434914462160854"}},"outputId":"904420b7-011c-43ac-a104-4474f995e79f"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"mwuzu1PuRwWi","colab_type":"code","colab":{}},"source":["class DiceLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","        \n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        #inputs = torch.sigmoid(inputs)       \n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.contiguous().view(-1)\n","        targets = targets.contiguous().view(-1)\n","        \n","        intersection = (inputs * targets).sum()                            \n","        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n","        \n","        return 1 - dice"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoF-Fd8MFEd_","colab_type":"code","colab":{}},"source":["class GeneralizedDiceLoss(nn.Module):\n","  \"\"\"\n","        Generalized Dice;\n","        Copy from: https://github.com/wolny/pytorch-3dunet/blob/6e5a24b6438f8c631289c10638a17dea14d42051/unet3d/losses.py#L75\n","        paper: https://arxiv.org/pdf/1707.03237.pdf\n","        tf code: https://github.com/NifTK/NiftyNet/blob/dev/niftynet/layer/loss_segmentation.py#L279\n","  \"\"\"\n","  def __init__(self, epsilon=1e-5, weight=None, ignore_index=None, sigmoid_normalization=True):\n","    super(GeneralizedDiceLoss, self).__init__()\n","    self.epsilon = epsilon\n","    self.register_buffer('weight', weight)\n","    self.ignore_index = ignore_index\n","    if sigmoid_normalization:\n","      self.normalization = nn.Sigmoid()\n","    else:\n","      self.normalization = nn.Softmax(dim=1)\n","\n","  def forward(self, input, target):\n","    # get probabilities from logits\n","    #input = self.normalization(input)\n","\n","    assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n","\n","    # mask ignore_index if present\n","    if self.ignore_index is not None:\n","        mask = target.clone().ne_(self.ignore_index)\n","        mask.requires_grad = False\n","\n","        input = input * mask\n","        target = target * mask\n","\n","    input = input.contiguous().view(-1)\n","    target = target.contiguous().view(-1)\n","\n","    target = target.float()\n","    target_sum = target.sum(-1)\n","    class_weights = Variable(1. / (target_sum * target_sum).clamp(min=self.epsilon), requires_grad=False)\n","\n","    intersect = (input * target).sum(-1) * class_weights\n","    if self.weight is not None:\n","        weight = Variable(self.weight, requires_grad=False)\n","        intersect = weight * intersect\n","    intersect = intersect.sum()\n","\n","    denominator = ((input + target).sum(-1) * class_weights).sum()\n","\n","    return 1. - 2. * intersect / denominator.clamp(min=self.epsilon)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nrHn0QOR2Tff","colab_type":"text"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"ZyumJKZLbUze","colab_type":"text"},"source":["Remember to specific model number underneath"]},{"cell_type":"code","metadata":{"id":"aAwT0wQs2p2o","colab_type":"code","colab":{}},"source":["model_number = 'base_Unet_3D'  #CHANGE MODEL VERSION HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"44q0ij9n6Zbl","colab_type":"code","colab":{}},"source":["##CHANGE HERE TO LOAD UNET MODELS##\n","LOAD_MODEL = False #HERE\n","\n","\n","with torch.no_grad(): #THIS MEANS NEED TO CREATE NEW NOTEBOOK EVERYTIME WANT TO CREATE NEW MODEL TO PRESERVE ARCHITECTURE\n","  UNet = UNet().to(device)\n","\n","optimizer_Unet = torch.optim.SGD(UNet.parameters(), lr=0.001, momentum=0.99) #need same optimiser\n","#optimizer_Unet = torch.optim.Adam(UNet.parameters(), lr=0.001) #need same optimiser\n","\n","if LOAD_MODEL == True:\n","  checkpoint = torch.load(nobackup_models + model_number +'_checkpoint.pth.tar')\n","  first_epoch = checkpoint['epoch']\n","  train_dice_loss_list = checkpoint['train_dice_loss_list']\n","  test_dice_loss_list = checkpoint['test_dice_loss_list']\n","  UNet.load_state_dict(checkpoint['model'])\n","  optimizer_Unet.load_state_dict(checkpoint['optimizer'])\n","\n","else:\n","  first_epoch = 0\n","  train_dice_loss_list = []\n","  test_dice_loss_list = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l6P9F6W62coq","colab_type":"code","colab":{}},"source":["def save_checkpoint(state, filename=model_number):\n","    full_path = nobackup_models + filename +'_checkpoint.pth.tar'\n","    torch.save(state, full_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtJIMd1a-6J7","colab_type":"code","colab":{}},"source":["#criterion_Dice = DiceLoss() #try new\n","criterion_Dice = GeneralizedDiceLoss() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tb4kfBGtI0Ew","colab_type":"code","colab":{}},"source":["def train_wrapper():\n","  trainloss = 0\n","  for patient, data in enumerate(train_loader):  #ONLY TESTED WITH BATCH SIZE 1  \n","    print(patient, end = ' ')\n","    optimizer_Unet.zero_grad()\n","\n","    element_trainloss = train_element(torch.from_numpy(data['data']), torch.from_numpy(data['seg'])) \n","    trainloss+= float(element_trainloss)\n","      \n","    element_trainloss.backward()\n","    optimizer_Unet.step()\n","\n","    print(element_trainloss)\n","\n","  print(\"\\n Train loss: \" + str(trainloss/(train_size))) \n","  train_dice_loss_list.append(trainloss/(train_size))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8aGozJrOmmM","colab_type":"code","colab":{}},"source":["def train_element(input_tensor, seg_map):\n","  input_tensor_axial = input_tensor.to(device) #change this\n","  seg_map_axial = seg_map.to(device)\n","        \n","  outputs = UNet(input_tensor_axial)\n","\n","  loss = criterion_Dice(outputs, seg_map_axial)\n","  return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZd34OlNI0HZ","colab_type":"code","colab":{}},"source":["def validation_wrapper():\n","  testloss = 0\n","  with torch.no_grad():\n","    for patient, (input_tensor, seg_map, affine, MRI_ID) in enumerate(test_loader): #ONLY WORKS WITH BATCH SIZE 1\n","      testloss += float(validation_step(input_tensor, seg_map))\n","\n","    print(\"Test loss: \" + str(testloss/(test_size)))\n","    test_dice_loss_list.append(testloss/(test_size))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8mMIRSMPCU9","colab_type":"code","colab":{}},"source":["def validation_step(input_tensor, seg_map):\n","  element_testloss = 0\n","  with torch.no_grad():\n","    optimizer_Unet.zero_grad()\n","    input_tensor_axial = input_tensor.to(device).float() #change this\n","    seg_map_axial = seg_map.to(device).float()\n","\n","    outputs = UNet(input_tensor_axial) \n","\n","    loss = criterion_Dice(outputs, seg_map_axial)\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9Tzkwx5xary","colab_type":"code","colab":{}},"source":["def train_3DUnet(num_epochs, do_validation=False):\n","  for epoch in range(num_epochs): #train the model MADE OF SEVERAL SUB FUNCTIONS IN AN ATTEMPT TO PREVENT MEMORY LEAKS!\n","    print(\"EPOCH \" + str(first_epoch+epoch+1))\n","    print(\" \")\n","    train_wrapper()\n","    if do_validation == True:\n","      validation_wrapper()\n","    print(\" \")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f2qHfhg-A4kf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"567579fa-baf2-4ca1-9575-4824dea6c6de"},"source":["num_epochs = 1\n","train_3DUnet(num_epochs, do_validation=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["EPOCH 1\n"," \n","0 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","1 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9979, grad_fn=<RsubBackward1>)\n","2 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","3 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7709, grad_fn=<RsubBackward1>)\n","4 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","5 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","6 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8938, grad_fn=<RsubBackward1>)\n","7 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8204, grad_fn=<RsubBackward1>)\n","8 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9143, grad_fn=<RsubBackward1>)\n","9 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","10 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","11 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","12 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7650, grad_fn=<RsubBackward1>)\n","13 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9854, grad_fn=<RsubBackward1>)\n","14 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9971, grad_fn=<RsubBackward1>)\n","15 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9951, grad_fn=<RsubBackward1>)\n","16 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9624, grad_fn=<RsubBackward1>)\n","17 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","18 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","19 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","20 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","21 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9842, grad_fn=<RsubBackward1>)\n","22 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8687, grad_fn=<RsubBackward1>)\n","23 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9979, grad_fn=<RsubBackward1>)\n","24 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","25 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9086, grad_fn=<RsubBackward1>)\n","26 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7325, grad_fn=<RsubBackward1>)\n","27 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","28 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8311, grad_fn=<RsubBackward1>)\n","29 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9042, grad_fn=<RsubBackward1>)\n","30 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7853, grad_fn=<RsubBackward1>)\n","31 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","32 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","33 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","34 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8711, grad_fn=<RsubBackward1>)\n","35 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9479, grad_fn=<RsubBackward1>)\n","36 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5918, grad_fn=<RsubBackward1>)\n","37 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7871, grad_fn=<RsubBackward1>)\n","38 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","39 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7948, grad_fn=<RsubBackward1>)\n","40 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","41 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9115, grad_fn=<RsubBackward1>)\n","42 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9443, grad_fn=<RsubBackward1>)\n","43 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7995, grad_fn=<RsubBackward1>)\n","44 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.6326, grad_fn=<RsubBackward1>)\n","45 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7225, grad_fn=<RsubBackward1>)\n","46 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","47 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","48 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9879, grad_fn=<RsubBackward1>)\n","49 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9997, grad_fn=<RsubBackward1>)\n","50 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9938, grad_fn=<RsubBackward1>)\n","51 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","52 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","53 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9932, grad_fn=<RsubBackward1>)\n","54 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8620, grad_fn=<RsubBackward1>)\n","55 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9753, grad_fn=<RsubBackward1>)\n","56 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.6317, grad_fn=<RsubBackward1>)\n","57 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9761, grad_fn=<RsubBackward1>)\n","58 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9971, grad_fn=<RsubBackward1>)\n","59 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9951, grad_fn=<RsubBackward1>)\n","60 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","61 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","62 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5005, grad_fn=<RsubBackward1>)\n","63 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","64 torch.Size([1, 4, 80, 80, 80])\n","tensor(1.0000, grad_fn=<RsubBackward1>)\n","65 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9364, grad_fn=<RsubBackward1>)\n","66 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.4716, grad_fn=<RsubBackward1>)\n","67 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8674, grad_fn=<RsubBackward1>)\n","68 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8022, grad_fn=<RsubBackward1>)\n","69 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","70 torch.Size([1, 4, 80, 80, 80])\n","tensor(1.0000, grad_fn=<RsubBackward1>)\n","71 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9486, grad_fn=<RsubBackward1>)\n","72 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9981, grad_fn=<RsubBackward1>)\n","73 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5324, grad_fn=<RsubBackward1>)\n","74 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8054, grad_fn=<RsubBackward1>)\n","75 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8374, grad_fn=<RsubBackward1>)\n","76 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.3196, grad_fn=<RsubBackward1>)\n","77 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9997, grad_fn=<RsubBackward1>)\n","78 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.4370, grad_fn=<RsubBackward1>)\n","79 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8945, grad_fn=<RsubBackward1>)\n","80 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","81 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","82 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","83 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","84 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","85 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","86 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","87 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","88 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7548, grad_fn=<RsubBackward1>)\n","89 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8315, grad_fn=<RsubBackward1>)\n","90 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","91 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.6119, grad_fn=<RsubBackward1>)\n","92 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8068, grad_fn=<RsubBackward1>)\n","93 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8565, grad_fn=<RsubBackward1>)\n","94 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","95 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","96 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","97 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7464, grad_fn=<RsubBackward1>)\n","98 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","99 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8828, grad_fn=<RsubBackward1>)\n","100 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","101 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","102 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7769, grad_fn=<RsubBackward1>)\n","103 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7329, grad_fn=<RsubBackward1>)\n","104 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8713, grad_fn=<RsubBackward1>)\n","105 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8390, grad_fn=<RsubBackward1>)\n","106 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7288, grad_fn=<RsubBackward1>)\n","107 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","108 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8616, grad_fn=<RsubBackward1>)\n","109 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","110 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7048, grad_fn=<RsubBackward1>)\n","111 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","112 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9075, grad_fn=<RsubBackward1>)\n","113 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9467, grad_fn=<RsubBackward1>)\n","114 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","115 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.4704, grad_fn=<RsubBackward1>)\n","116 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9995, grad_fn=<RsubBackward1>)\n","117 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9440, grad_fn=<RsubBackward1>)\n","118 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","119 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8747, grad_fn=<RsubBackward1>)\n","120 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9992, grad_fn=<RsubBackward1>)\n","121 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5116, grad_fn=<RsubBackward1>)\n","122 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7859, grad_fn=<RsubBackward1>)\n","123 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","124 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8597, grad_fn=<RsubBackward1>)\n","125 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","126 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8901, grad_fn=<RsubBackward1>)\n","127 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","128 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8240, grad_fn=<RsubBackward1>)\n","129 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9080, grad_fn=<RsubBackward1>)\n","130 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","131 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8548, grad_fn=<RsubBackward1>)\n","132 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","133 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.6168, grad_fn=<RsubBackward1>)\n","134 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8097, grad_fn=<RsubBackward1>)\n","135 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","136 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9028, grad_fn=<RsubBackward1>)\n","137 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8806, grad_fn=<RsubBackward1>)\n","138 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9937, grad_fn=<RsubBackward1>)\n","139 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.3037, grad_fn=<RsubBackward1>)\n","140 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","141 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5477, grad_fn=<RsubBackward1>)\n","142 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.6307, grad_fn=<RsubBackward1>)\n","143 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7490, grad_fn=<RsubBackward1>)\n","144 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9271, grad_fn=<RsubBackward1>)\n","145 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","146 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","147 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9057, grad_fn=<RsubBackward1>)\n","148 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9991, grad_fn=<RsubBackward1>)\n","149 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8889, grad_fn=<RsubBackward1>)\n","150 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","151 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","152 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5742, grad_fn=<RsubBackward1>)\n","153 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8110, grad_fn=<RsubBackward1>)\n","154 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5917, grad_fn=<RsubBackward1>)\n","155 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.6282, grad_fn=<RsubBackward1>)\n","156 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7531, grad_fn=<RsubBackward1>)\n","157 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9988, grad_fn=<RsubBackward1>)\n","158 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9930, grad_fn=<RsubBackward1>)\n","159 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","160 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9896, grad_fn=<RsubBackward1>)\n","161 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.6338, grad_fn=<RsubBackward1>)\n","162 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.3753, grad_fn=<RsubBackward1>)\n","163 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9993, grad_fn=<RsubBackward1>)\n","164 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5990, grad_fn=<RsubBackward1>)\n","165 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","166 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","167 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","168 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7611, grad_fn=<RsubBackward1>)\n","169 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","170 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","171 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","172 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5475, grad_fn=<RsubBackward1>)\n","173 torch.Size([1, 4, 80, 80, 80])\n","tensor(1.0000, grad_fn=<RsubBackward1>)\n","174 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9006, grad_fn=<RsubBackward1>)\n","175 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9691, grad_fn=<RsubBackward1>)\n","176 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9910, grad_fn=<RsubBackward1>)\n","177 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9658, grad_fn=<RsubBackward1>)\n","178 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","179 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5042, grad_fn=<RsubBackward1>)\n","180 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","181 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7137, grad_fn=<RsubBackward1>)\n","182 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9983, grad_fn=<RsubBackward1>)\n","183 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","184 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9418, grad_fn=<RsubBackward1>)\n","185 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7274, grad_fn=<RsubBackward1>)\n","186 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9854, grad_fn=<RsubBackward1>)\n","187 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5137, grad_fn=<RsubBackward1>)\n","188 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","189 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","190 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9096, grad_fn=<RsubBackward1>)\n","191 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","192 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5971, grad_fn=<RsubBackward1>)\n","193 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.5872, grad_fn=<RsubBackward1>)\n","194 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","195 torch.Size([1, 4, 80, 80, 80])\n","tensor(1.0000, grad_fn=<RsubBackward1>)\n","196 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","197 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","198 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7019, grad_fn=<RsubBackward1>)\n","199 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","200 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","201 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","202 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9737, grad_fn=<RsubBackward1>)\n","203 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9993, grad_fn=<RsubBackward1>)\n","204 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9463, grad_fn=<RsubBackward1>)\n","205 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","206 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.6772, grad_fn=<RsubBackward1>)\n","207 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","208 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9199, grad_fn=<RsubBackward1>)\n","209 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7952, grad_fn=<RsubBackward1>)\n","210 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7706, grad_fn=<RsubBackward1>)\n","211 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8634, grad_fn=<RsubBackward1>)\n","212 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.6527, grad_fn=<RsubBackward1>)\n","213 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","214 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","215 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","216 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","217 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9918, grad_fn=<RsubBackward1>)\n","218 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","219 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.9492, grad_fn=<RsubBackward1>)\n","220 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.8939, grad_fn=<RsubBackward1>)\n","221 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","222 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","223 torch.Size([1, 4, 80, 80, 80])\n","tensor(1., grad_fn=<RsubBackward1>)\n","224 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.7450, grad_fn=<RsubBackward1>)\n","225 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.3183, grad_fn=<RsubBackward1>)\n","226 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.6095, grad_fn=<RsubBackward1>)\n","227 torch.Size([1, 4, 80, 80, 80])\n","tensor(0.4815, grad_fn=<RsubBackward1>)\n","\n"," Train loss: 0.8845094379625822\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H450W1034boS","colab_type":"code","colab":{}},"source":["save_checkpoint({\n","            'epoch': first_epoch+num_epochs,\n","            'model': UNet.state_dict(),\n","            'train_dice_loss_list': train_dice_loss_list,\n","            'test_dice_loss_list': test_dice_loss_list,\n","            'optimizer' : optimizer_Unet.state_dict()\n","            }\n","            ) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ZZydFrv7rVq","colab_type":"text"},"source":["##Post processing"]},{"cell_type":"code","metadata":{"id":"DLHbKTYNOKhf","colab_type":"code","colab":{}},"source":["def get_short_id(long_id):\n","  short_id = \"\"\n","  for i in range(len(long_id)-5): #ignore the first 4 characters\n","    if long_id[i+4] == '/':\n","      return short_id\n","    else:\n","      short_id += long_id[i+4]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4bf08PiCEZj9","colab_type":"code","colab":{}},"source":["def save_results():\n","  newpath = nobackup_models + model_number + '_Results'\n","  if not os.path.exists(newpath):\n","    os.makedirs(newpath)\n","  with torch.no_grad():\n","    for patient, (input_tensor, seg_map, affine, MRI_ID) in enumerate(full_loader):\n","      print(patient, end = ' ')\n","      seg_3D = get_seg_wrapper(input_tensor).detach().cpu()\n","\n","      ID = get_short_id(MRI_ID[0])\n","      ni_img = nib.Nifti1Image(seg_3D.numpy(), affine.reshape(4, 4))\n","      nib.save(ni_img, newpath + '/' + ID + '.nii.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwF8PH-Ac8tp","colab_type":"code","colab":{}},"source":["def get_seg_wrapper(input_tensor):\n","  with torch.no_grad():\n","    input_tensor_axial = input_tensor.float().to(device) #change this\n","    return UNet(input_tensor_axial)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vymkcQ5rWnsK","colab_type":"code","colab":{}},"source":["finalize = False #CHANGE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0yDOr-JWwST","colab_type":"code","colab":{}},"source":["if finalize == True:\n","  save_results()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Ud879-cD8_x","colab_type":"text"},"source":["##NOTES"]},{"cell_type":"code","metadata":{"id":"n8e2nmDzRVpR","colab_type":"code","colab":{}},"source":["#start making actual comparison of models\n","#start referencing / ordering"],"execution_count":null,"outputs":[]}]}