{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Base GAN GPU.ipynb","provenance":[{"file_id":"1AWOpUpOa2I7N7-qxMK3U3RZIXj6idg4n","timestamp":1595948218178},{"file_id":"1WNe9cvMG-tFuuPtd2VZwd6paZIdG-WfT","timestamp":1594145306822}],"collapsed_sections":["M03a0Rx_G8qk","De-sVZQJYsdh","Jwyn3cHR2l7x","vUS4yesNi-JJ"],"authorship_tag":"ABX9TyOZlVD8owDPbxqZARi0ZgGs"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JEgNgZ_YMIhS","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import gzip, shutil\n","import nibabel as nib\n","import time\n","import random\n","\n","import torch\n","from torch.utils.data import Dataset\n","\n","import torch.nn.functional as F\n","from torch import nn as nn\n","from torch.autograd import Variable\n","from torch.nn import MSELoss, SmoothL1Loss, L1Loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lf5gzSda86e6","colab_type":"code","colab":{}},"source":["nobackup = '/nobackup/sc19rw/Train/'\n","nobackup_models = '/nobackup/sc19rw/Models/'\n","home = '/home/home01/sc19rw/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M03a0Rx_G8qk","colab_type":"text"},"source":["## Data collection"]},{"cell_type":"code","metadata":{"id":"fwkeVBofs49S","colab_type":"code","colab":{}},"source":["def get_random_crop(img,cropx,cropy,cropz):\n","    x,y,z = img.shape\n","    startx = random.randint(0,(x-cropx))\n","    starty = random.randint(0,(y-cropy))\n","    startz = random.randint(0,(z-cropz))\n","    return startx, starty, startz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBLl5JlQwCVE","colab_type":"code","colab":{}},"source":["MRI_ids = np.load(home+\"MRI_ids.npz\") #make sure you use the .npz!\n","MRI_ids = MRI_ids['arr_0']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-iIj__UImW2I","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import random\n","\n","\n","root = nobackup\n","\n","data = {\n","    'image_id': MRI_ids,\n","    't1_path': [root + MRI_id + \"_t1_norm\"+ \".nii\" for MRI_id in MRI_ids],\n","    't1ce_path': [root + MRI_id + \"_t1ce_norm\" + \".nii\" for MRI_id in MRI_ids],\n","    'flair_path': [root + MRI_id + \"_flair_norm\" + \".nii\" for MRI_id in MRI_ids],\n","    't2_path': [root + MRI_id + \"_t2_norm\" + \".nii\" for MRI_id in MRI_ids],\n","    'seg_path': [root + MRI_id + \"_seg\" + \".nii\" for MRI_id in MRI_ids],\n","}\n","\n","data_df = pd.DataFrame(data, columns=['image_id', 't1_path', 't1ce_path', 'flair_path', 't2_path', 'seg_path'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePs10Qr_pAEC","colab_type":"code","colab":{}},"source":["class BRATS_DATA_CROPPED(Dataset):\n","    \"\"\" BRATS custom dataset compatible with torch.utils.data.DataLoader. \"\"\"\n","    \n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","\n","        MRI_id = self.df['image_id'][index] \n","        t1_path = self.df['t1_path'][index]\n","        t1ce_path = self.df['t1ce_path'][index]\n","        flair_path = self.df['flair_path'][index]\n","        t2_path = self.df['t2_path'][index]\n","        seg_path = self.df['seg_path'][index]\n","\n","        seg_map = nib.load(seg_path)\n","        affine = seg_map.affine\n","\n","        seg_map = seg_map.get_fdata()\n","\n","        cropx,cropy,cropz = 160, 160, 128\n","        startx,starty,startz = get_random_crop(seg_map, cropx,cropy,cropz)\n","\n","        t1_MRI = nib.load(t1_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        t1ce_MRI = nib.load(t1ce_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        flair_MRI = nib.load(flair_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        t2_MRI = nib.load(t2_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        seg_map = seg_map[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","\n","        \n","        input_tensor = np.concatenate((t1_MRI, t1ce_MRI, flair_MRI, t2_MRI), axis=0) \n","     \n","\n","        return input_tensor, seg_map, affine, MRI_id\n","\n","    def __len__(self):\n","        return len(self.df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3EPRK3gbtG0i","colab_type":"code","colab":{}},"source":["class BRATS_DATA(Dataset):\n","    \"\"\" BRATS custom dataset compatible with torch.utils.data.DataLoader. \"\"\"\n","    \n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","\n","        MRI_id = self.df['image_id'][index] \n","        t1_path = self.df['t1_path'][index]\n","        t1ce_path = self.df['t1ce_path'][index]\n","        flair_path = self.df['flair_path'][index]\n","        t2_path = self.df['t2_path'][index]\n","        seg_path = self.df['seg_path'][index]\n","\n","        seg_map = nib.load(seg_path)\n","        affine = seg_map.affine\n","\n","        t1_MRI = nib.load(t1_path).get_fdata()[:].reshape(1,240,240,155)\n","        t1ce_MRI = nib.load(t1ce_path).get_fdata()[:].reshape(1,240,240,155)\n","        flair_MRI = nib.load(flair_path).get_fdata()[:].reshape(1,240,240,155)\n","        t2_MRI = nib.load(t2_path).get_fdata()[:].reshape(1,240,240,155)\n","        seg_map = seg_map.get_fdata()[:].reshape(1,240,240,155)\n","\n","        \n","        input_tensor = np.concatenate((t1_MRI, t1ce_MRI, flair_MRI, t2_MRI), axis=0) \n","     \n","\n","        return input_tensor, seg_map, affine, MRI_id\n","\n","    def __len__(self):\n","        return len(self.df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvd4iZdXxFJq","colab_type":"code","colab":{}},"source":["train_split = 0.8 # Defines the ratio of train/test data.\n","\n","train_size = round(len(data_df)*train_split)\n","test_size = round(len(data_df)*(1-train_split))\n","\n","dataset_train = BRATS_DATA_CROPPED(\n","    df=data_df[:train_size].reset_index(drop=True),\n",")\n","\n","dataset_test = BRATS_DATA_CROPPED(\n","    df=data_df[-test_size:].reset_index(drop=True),\n",")\n","\n","dataset_total = BRATS_DATA( #used to get the final segmentations\n","    df=data_df[:len(data_df)].reset_index(drop=True),\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"De-sVZQJYsdh","colab_type":"text"},"source":["##Data Augmentation"]},{"cell_type":"code","metadata":{"id":"ObGhn7nyAjyH","colab_type":"code","colab":{}},"source":["from batchgenerators.dataloading.data_loader import DataLoaderBase\n","from batchgenerators.transforms.abstract_transforms import Compose\n","from batchgenerators.dataloading.single_threaded_augmenter import SingleThreadedAugmenter\n","from batchgenerators.transforms.spatial_transforms import SpatialTransform_2\n","from batchgenerators.transforms.spatial_transforms import SpatialTransform\n","from batchgenerators.transforms.spatial_transforms import MirrorTransform\n","from batchgenerators.transforms.color_transforms import GammaTransform"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L6JRNV1GSjxf","colab_type":"code","colab":{}},"source":["class DataLoader(DataLoaderBase): #SlimDataLoaderBase \n","    def __init__(self, data, BATCH_SIZE=1, num_batches=None, seed=False):\n","        super(DataLoader, self).__init__(data, BATCH_SIZE, num_batches, seed) \n","        # data is now stored in self._data.\n","        self.index = 0\n","        self.batch_size = BATCH_SIZE\n","    \n","    def generate_train_batch(self):\n","        currentindex = self.index\n","        self.index += 1\n","        if self.index % len(self._data)  == 0:\n","          self.index = 0\n","\n","        data = self._data[self.index][0].reshape(self.batch_size, 4, 160, 160, 128)   #.numpy()\n","        seg = self._data[self.index][1].reshape(self.batch_size, 1, 160, 160, 128)\n","\n","        return {'data':data, 'seg':seg, 'affine':self._data[self.index][2], 'MRI_ID':self._data[self.index][3]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxf_Q4AZT1BT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1595935860970,"user_tz":-120,"elapsed":11856,"user":{"displayName":"Robin W","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1oQMkhoLuxB7sheDY7dP0v-uCx_Q9NOcBrD4=s64","userId":"07744434914462160854"}},"outputId":"07b37c15-d9a1-4b42-b85b-f38013e9b5fc"},"source":["batchgen = DataLoader(dataset_train, 1, len(dataset_train), False) #Basic data loader without augmentation"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/batchgenerators/dataloading/data_loader.py:53: DeprecationWarning: This DataLoader will soon be removed. Migrate everything to SlimDataLoaderBase now!\n","  warn(\"This DataLoader will soon be removed. Migrate everything to SlimDataLoaderBase now!\", DeprecationWarning)\n","/usr/local/lib/python3.6/dist-packages/batchgenerators/dataloading/data_loader.py:58: UserWarning: We currently strongly discourage using num_batches != None! That does not seem to work properly\n","  warn(\"We currently strongly discourage using num_batches != None! That does not seem to work properly\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"SoBE6d2mjGtK","colab_type":"code","colab":{}},"source":["my_transforms = [] #define all augmentation techniques to be applied\n","\n","spatial_transform = SpatialTransform(\n","            dataset_train[0][0][0].shape, dataset_train[0][0][0].shape,\n","            do_elastic_deform=True,\n","            alpha=(0., 175.), sigma=(10., 13.),       \n","            do_rotation=True,\n","            angle_x=(- 5 / 360. * 2 * np.pi, 5 / 360. * 2 * np.pi),\n","            angle_y=(- 5 / 360. * 2 * np.pi, 5 / 360. * 2 * np.pi),\n","            angle_z=(- 5 / 360. * 2 * np.pi, 5 / 360. * 2 * np.pi),\n","            do_scale=True, scale=(0.9, 1.02),\n","            border_mode_data='constant', border_cval_data=0,\n","            border_mode_seg='constant', border_cval_seg=0,\n","            order_seg=1, order_data=3,\n","            random_crop=False,\n","            p_el_per_sample=0.1, p_rot_per_sample=0.1, p_scale_per_sample=0.1)\n","\n","\n","my_transforms.append(spatial_transform)\n","my_transforms.append(MirrorTransform(axes=(0, 1, 2)))\n","my_transforms.append(GammaTransform(gamma_range=(0.7, 1.), invert_image=False, per_channel=True, p_per_sample=0.1))\n","\n","all_transforms = Compose(my_transforms)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoFp9_AFhizK","colab_type":"code","colab":{}},"source":["train_loader = SingleThreadedAugmenter(batchgen, all_transforms) #data loader for training, applying on the fly transformation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"70xp8dPKyBfT","colab_type":"code","colab":{}},"source":["# add other data loaders\n","test_loader = torch.utils.data.DataLoader(\n","    dataset_test,\n","    batch_size=1, \n","    shuffle=False,\n","    num_workers=0,\n",")\n","\n","full_loader = torch.utils.data.DataLoader(\n","    dataset_total,\n","    batch_size=1, \n","    shuffle=False,\n","    num_workers=0,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jwyn3cHR2l7x","colab_type":"text"},"source":["## Building Model \n","\n"]},{"cell_type":"code","metadata":{"id":"5W-2KtVyL9-Q","colab_type":"code","colab":{}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class UNet(nn.Module):\n","    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n","                    torch.nn.LeakyReLU(), \n","                    torch.nn.InstanceNorm2d(out_channels), \n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm2d(out_channels),\n","                )\n","        return block\n","    \n","    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","            block = torch.nn.Sequential(\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm2d(mid_channel),\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm2d(mid_channel),\n","                    torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n","                    )\n","            return  block\n","    \n","    def bottleneck_block(self):\n","           block = torch.nn.Sequential(   #put this properly before\n","                            torch.nn.Conv2d(kernel_size=3, in_channels=240, out_channels=480, padding=1),\n","                            torch.nn.LeakyReLU(),\n","                            torch.nn.InstanceNorm2d(480),\n","                            torch.nn.Conv2d(kernel_size=3, in_channels=480, out_channels=240, padding=1),\n","                            torch.nn.LeakyReLU(),\n","                            torch.nn.InstanceNorm2d(240),\n","                            torch.nn.ConvTranspose2d(in_channels=240, out_channels=240, kernel_size=3, stride=2, padding=1, output_padding=1)\n","                            )\n","           return block\n","\n","    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","            block = torch.nn.Sequential(\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm2d(mid_channel),\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm2d(mid_channel),\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n","                    #torch.nn.LeakyReLU(),\n","                    torch.nn.Sigmoid(),\n","                    )\n","            return  block\n","    \n","    def __init__(self):\n","        super(UNet, self).__init__()       \n","        #Encode\n","        self.conv_encode1 = self.contracting_block(in_channels=4, out_channels=30)\n","        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n","        self.conv_encode2 = self.contracting_block(30, 60)\n","        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n","        self.conv_encode3 = self.contracting_block(60, 120)\n","        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n","        self.conv_encode4 = self.contracting_block(120, 240)\n","        self.conv_maxpool4 = torch.nn.MaxPool2d(kernel_size=2)\n","        # Bottleneck\n","        self.bottleneck = self.bottleneck_block()\n","        # Decode\n","        self.conv_decode4 = self.expansive_block(480, 240, 120)\n","        self.conv_decode3 = self.expansive_block(240, 120, 60)\n","        self.conv_decode2 = self.expansive_block(120, 60, 30)\n","        self.final_layer = self.final_block(60, 30, 1)\n","        \n","    \n","    def forward(self, input_tensor):\n","        # Encode\n","        encode_block1 = self.conv_encode1(input_tensor)\n","        encode_pool1 = self.conv_maxpool1(encode_block1)\n","        encode_block2 = self.conv_encode2(encode_pool1)\n","        encode_pool2 = self.conv_maxpool2(encode_block2)\n","        encode_block3 = self.conv_encode3(encode_pool2)\n","        encode_pool3 = self.conv_maxpool3(encode_block3)\n","        encode_block4 = self.conv_encode4(encode_pool3)\n","        encode_pool4 = self.conv_maxpool4(encode_block4)\n","        # Bottleneck\n","        bottleneck1 = self.bottleneck(encode_pool4)\n","        # Decode\n","        decode_block4 = self.conv_decode4(torch.cat((bottleneck1, encode_block4), 1))\n","        decode_block3 = self.conv_decode3(torch.cat((decode_block4, encode_block3), 1))\n","        decode_block2 = self.conv_decode2(torch.cat((decode_block3, encode_block2), 1))\n","\n","        final_layer = self.final_layer(torch.cat((decode_block2, encode_block1), 1))\n","        return  final_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RkNObtdBd6Qb","colab_type":"code","colab":{}},"source":["class Discriminator(nn.Module):\n","    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n","                    torch.nn.LeakyReLU(), \n","                    torch.nn.InstanceNorm2d(out_channels), \n","                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm2d(out_channels),\n","                )\n","        return block\n","    \n","    def __init__(self):\n","        super(Discriminator, self).__init__()       \n","        self.conv_encode1 = self.contracting_block(in_channels=5, out_channels=30)\n","        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n","        self.conv_encode2 = self.contracting_block(30, 60)\n","        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n","        self.conv_encode3 = self.contracting_block(60, 120)\n","        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n","        self.conv_encode4 = self.contracting_block(120, 240)\n","        self.conv_maxpool4 = torch.nn.MaxPool2d(kernel_size=2)\n","        self.final_layer1 = torch.nn.Conv2d(kernel_size=3, in_channels=240, out_channels=480, padding=1)\n","        self.final_layer2 = torch.nn.Conv2d(kernel_size=3, in_channels=480, out_channels=1, padding=1)\n","        self.final_activation = torch.nn.Sigmoid()\n","    \n","    def forward(self, input_tensor):\n","        encode_block1 = self.conv_encode1(input_tensor)\n","        encode_pool1 = self.conv_maxpool1(encode_block1)\n","        encode_block2 = self.conv_encode2(encode_pool1)\n","        encode_pool2 = self.conv_maxpool2(encode_block2)\n","        encode_block3 = self.conv_encode3(encode_pool2)\n","        encode_pool3 = self.conv_maxpool3(encode_block3)\n","        encode_block4 = self.conv_encode4(encode_pool3)\n","        encode_pool4 = self.conv_maxpool4(encode_block4)\n","        output = self.final_layer1(encode_pool4)\n","        output = self.final_layer2(output)\n","        output = self.final_activation(output)\n","\n","        return  output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JXGRiG_tJIco","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1595935865955,"user_tz":-120,"elapsed":16820,"user":{"displayName":"Robin W","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1oQMkhoLuxB7sheDY7dP0v-uCx_Q9NOcBrD4=s64","userId":"07744434914462160854"}},"outputId":"5b6c3313-f113-4086-944e-62a67f1768eb"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"mwuzu1PuRwWi","colab_type":"code","colab":{}},"source":["class DiceLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","        \n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        #inputs = torch.sigmoid(inputs)       \n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.contiguous().view(-1)\n","        targets = targets.contiguous().view(-1)\n","        \n","        intersection = (inputs * targets).sum()                            \n","        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n","        \n","        return 1 - dice"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoF-Fd8MFEd_","colab_type":"code","colab":{}},"source":["class GeneralizedDiceLoss(nn.Module):\n","  \"\"\"\n","        Generalized Dice;\n","        Copy from: https://github.com/wolny/pytorch-3dunet/blob/6e5a24b6438f8c631289c10638a17dea14d42051/unet3d/losses.py#L75\n","        paper: https://arxiv.org/pdf/1707.03237.pdf\n","        tf code: https://github.com/NifTK/NiftyNet/blob/dev/niftynet/layer/loss_segmentation.py#L279\n","  \"\"\"\n","  def __init__(self, epsilon=1e-5, weight=None, ignore_index=None, sigmoid_normalization=True):\n","    super(GeneralizedDiceLoss, self).__init__()\n","    self.epsilon = epsilon\n","    self.register_buffer('weight', weight)\n","    self.ignore_index = ignore_index\n","    if sigmoid_normalization:\n","      self.normalization = nn.Sigmoid()\n","    else:\n","      self.normalization = nn.Softmax(dim=1)\n","\n","  def forward(self, input, target):\n","    # get probabilities from logits\n","    #input = self.normalization(input)\n","\n","    assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n","\n","    # mask ignore_index if present\n","    if self.ignore_index is not None:\n","        mask = target.clone().ne_(self.ignore_index)\n","        mask.requires_grad = False\n","\n","        input = input * mask\n","        target = target * mask\n","\n","    input = input.contiguous().view(-1)\n","    target = target.contiguous().view(-1)\n","\n","    target = target.float()\n","    target_sum = target.sum(-1)\n","    class_weights = Variable(1. / (target_sum * target_sum).clamp(min=self.epsilon), requires_grad=False)\n","\n","    intersect = (input * target).sum(-1) * class_weights\n","    if self.weight is not None:\n","        weight = Variable(self.weight, requires_grad=False)\n","        intersect = weight * intersect\n","    intersect = intersect.sum()\n","\n","    denominator = ((input + target).sum(-1) * class_weights).sum()\n","\n","    return 1. - 2. * intersect / denominator.clamp(min=self.epsilon)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nrHn0QOR2Tff","colab_type":"text"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"brefge53R4tN","colab_type":"text"},"source":["Dont forget to change model number"]},{"cell_type":"code","metadata":{"id":"8qqaVV2FR4TN","colab_type":"code","colab":{}},"source":["model_number = 'base_GAN_Crop'  #CHANGE MODEL VERSION HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IhCZbzoXR8-D","colab_type":"code","colab":{}},"source":["##CHANGE HERE TO LOAD UNET MODELS##\n","LOAD_MODEL = False #HERE\n","\n","\n","with torch.no_grad(): #THIS MEANS NEED TO CREATE NEW NOTEBOOK EVERYTIME WANT TO CREATE NEW MODEL TO PRESERVE ARCHITECTURE\n","  UNet = UNet().to(device)\n","  Discriminator = Discriminator().to(device)\n","\n","optimizer_Unet = torch.optim.SGD(UNet.parameters(), lr=0.001, momentum=0.99)\n","optimizer_Dis = torch.optim.SGD(Discriminator.parameters(), lr=0.001, momentum=0.99)\n","\n","if LOAD_MODEL == True:\n","  checkpoint = torch.load(nobackup_models + model_number +'_checkpoint.pth.tar')\n","  first_epoch = checkpoint['epoch']\n","  train_dice_loss_list = checkpoint['train_dice_loss_list']\n","  test_dice_loss_list = checkpoint['test_dice_loss_list']\n","  train_loss_list = checkpoint['train_loss_list']\n","  test_loss_list = checkpoint['test_loss_list']\n","  UNet.load_state_dict(checkpoint['UNet'])\n","  Discriminator.load_state_dict(checkpoint['Dis'])\n","  optimizer_Unet.load_state_dict(checkpoint['optimizer_Unet'])\n","  optimizer_Dis.load_state_dict(checkpoint['optimizer_Dis'])\n","\n","else:\n","  first_epoch = 0\n","  train_dice_loss_list = []\n","  test_dice_loss_list = []\n","  train_loss_list = []\n","  test_loss_list = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqf3leV_UyEX","colab_type":"code","colab":{}},"source":["def save_checkpoint(state, filename=model_number):\n","    full_path = nobackup_models + filename +'_checkpoint.pth.tar'\n","    torch.save(state, full_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PPRJvcZKI9Ml","colab_type":"code","colab":{}},"source":["#criterion_Dice = DiceLoss() #try new\n","criterion_Dice = GeneralizedDiceLoss() \n","criterion_Dis = torch.nn.MSELoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQbYRCA7MEaY","colab_type":"code","colab":{}},"source":["def train_GAN(num_epochs, do_validation, lambda_val = 5):\n","  isreal = torch.Tensor(np.ones((10,10)).reshape(1, 1, 10, 10)).to(device)\n","  isfake = torch.Tensor(np.zeros((10,10)).reshape(1, 1, 10, 10)).to(device)\n","  for epoch in range(num_epochs): #train the model THIS IS TO BE USED WHEN THE ARRAYS CANNOT FIT IN MEMORY\n","    trainloss = 0\n","    testloss = 0\n","    traindiceloss = 0\n","    testdiceloss = 0\n","\n","    print(\"NEW EPOCH\")\n","    for patient, data in enumerate(train_loader): #ONLY TESTED WITH BATCH SIZE 1\n","      input_tensor = torch.from_numpy(data['data'])\n","      seg_map = torch.from_numpy(data['seg'])\n","      print(patient, end = ' ')\n","      for i in range(128):\n","        optimizer_Dis.zero_grad() #reset\n","\n","        input_tensor_axial = input_tensor.float()[:,:,:,:,i].to(device) #get input slice\n","        real_seg_axial = seg_map.float()[:,:,:,:,i].to(device) #get corresponding segmentation slice\n","        \n","        fake_seg_axial = UNet(input_tensor_axial) #get predicted segmentation\n","\n","        pred_real = Discriminator(torch.cat((real_seg_axial, input_tensor_axial), 1)) #get discriminator predictions for both real and fake segmentation\n","        pred_fake = Discriminator(torch.cat((fake_seg_axial, input_tensor_axial), 1))\n","\n","        loss_real = criterion_Dis(pred_real, isreal) #get loss values for both real and fake segmentation\n","        loss_fake = criterion_Dis(pred_fake, isfake) \n","\n","        loss_Dis = 0.5 * (loss_real + loss_fake) #total loss for discriminator   \n","\n","        #print(loss_Dis)\n","        #FIRST TRAIN DISCRIMINATOR \n","\n","        loss_Dis.backward() #Dis loss\n","        optimizer_Dis.step() #Optimise discriminator\n","\n","        #SECOND TRAIN UNET\n","        optimizer_Unet.zero_grad() \n","        optimizer_Dis.zero_grad() \n","\n","        \n","        fake_seg_axial = UNet(input_tensor_axial) #get predicted segmentation\n","        pred_fake = Discriminator(torch.cat((fake_seg_axial, input_tensor_axial), 1)) #Get new generator output (can be deleted and use previous)\n","\n","        loss_dice = criterion_Dice(fake_seg_axial, real_seg_axial) #Get dice loss for Unet\n","        loss_fake = criterion_Dis(pred_fake, isreal) #Get descriminator loss for Unet\n","\n","        loss_Unet = loss_fake + lambda_val * loss_dice #Total UNet loss\n","        #print(\"loss U\")  \n","        #print(loss_Unet)\n","        loss_Unet.backward() \n","        optimizer_Unet.step() #Optimise Unet generator\n","\n","        trainloss += float(loss_Unet) \n","        traindiceloss += float(loss_dice)   \n","\n","    print(\"\\n Train total loss: \" + str(trainloss/(train_size*128))) \n","    print(\"Train Dice loss: \" + str(traindiceloss/(train_size*128))) \n","    train_dice_loss_list.append(traindiceloss/(train_size*128))\n","    train_loss_list.append(trainloss/(train_size*128))\n","\n","\n","    #VALIDATION \n","    if do_validation == True:\n","      with torch.no_grad():\n","        for patient, (input_tensor, seg_map, affine, MRI_ID) in enumerate(test_loader): #ONLY WORKS WITH BATCH SIZE 1\n","          for i in range(128):\n","            input_tensor_axial = input_tensor.float()[:,:,:,:,i].to(device).float() #get input slice\n","            real_seg_axial = seg_map.float()[:,:,:,:,i].to(device).float() #get corresponding segmentation slice\n","        \n","            fake_seg_axial = UNet(input_tensor_axial) #get predicted segmentation\n","            pred_fake = Discriminator(torch.cat((fake_seg_axial, input_tensor_axial), 1))\n","\n","\n","            loss_dice = criterion_Dice(fake_seg_axial, real_seg_axial)\n","            loss_fake = criterion_Dis(pred_fake, isfake)\n","\n","            loss_Unet = loss_fake + lambda_val * loss_dice\n","\n","            testloss += float(loss_Unet) \n","            testdiceloss += float(loss_dice)   \n","        print(\"Test loss: \" + str(testloss/(test_size*128)))\n","        print(\"Test Dice loss: \" + str(testdiceloss/(test_size*128))) \n","        test_dice_loss_list.append(testdiceloss/(test_size*128))\n","        test_loss_list.append(testloss/(test_size*128))\n","\n","    print(\" \")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RRM6W2AMEwe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"7ff2ed78-48d5-46fb-803a-2fabf7ff51f8"},"source":["num_epochs = 1\n","train_GAN(num_epochs, do_validation=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["NEW EPOCH\n","0 1 "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uHnxiAFTU6VJ","colab_type":"code","colab":{}},"source":["save_checkpoint({\n","            'epoch': first_epoch+num_epochs,\n","            'UNet': UNet.state_dict(),\n","            'Dis': Discriminator.state_dict(),\n","            'train_dice_loss_list': train_dice_loss_list,\n","            'test_dice_loss_list': test_dice_loss_list,\n","            'train_loss_list': train_loss_list,\n","            'test_loss_list': test_loss_list,\n","            'optimizer_Unet' : optimizer_Unet.state_dict(),\n","            'optimizer_Dis' : optimizer_Dis.state_dict()\n","            }\n","            ) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vUS4yesNi-JJ"},"source":["##Post processing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xHvcrIuei-JM","colab":{}},"source":["def get_short_id(long_id):\n","  short_id = \"\"\n","  for i in range(len(long_id)-5): #ignore the first 4 characters\n","    if long_id[i+4] == '/':\n","      return short_id\n","    else:\n","      short_id += long_id[i+4]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lm_oZDm6i-JY","colab":{}},"source":["def save_results():\n","  newpath = nobackup_models + model_number + '_Results'\n","  if not os.path.exists(newpath):\n","    os.makedirs(newpath)\n","  with torch.no_grad():\n","    for patient, (input_tensor, seg_map, affine, MRI_ID) in enumerate(full_loader):\n","      print(patient, end = ' ')\n","      print(input_tensor.shape)\n","      for i in range(155):\n","        seg = get_seg_wrapper(input_tensor, i).detach().cpu()\n","        if i == 0:\n","          seg_3D = seg\n","        else:\n","          seg_3D = torch.cat((seg_3D, seg), 4)\n","      ID = get_short_id(MRI_ID[0])\n","      ni_img = nib.Nifti1Image(seg_3D.numpy(), affine.reshape(4, 4))\n","      nib.save(ni_img, newpath + '/' + ID + '.nii.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwF8PH-Ac8tp","colab_type":"code","colab":{}},"source":["def get_seg_wrapper(input_tensor, i):\n","  with torch.no_grad():\n","    input_tensor_axial = input_tensor.float()[:,:,:,:,i].to(device) #change this\n","    return UNet(input_tensor_axial).reshape(1, 1, 240, 240, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VcseMbAci-Jm","colab":{}},"source":["finalize = False #CHANGE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hCTUYp_ri-Js","colab":{}},"source":["if finalize == True:\n","  save_results()"],"execution_count":null,"outputs":[]}]}