{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN 3D Asy Decoder GPU.ipynb","provenance":[{"file_id":"1zfvPBgARWuIFnTgl6et18Txt8ptiiRI2","timestamp":1596275025957},{"file_id":"1O4JDJXSeemR6axzd8kWbza4nUmb5_qUH","timestamp":1595948243815},{"file_id":"1AWOpUpOa2I7N7-qxMK3U3RZIXj6idg4n","timestamp":1595931238824},{"file_id":"1WNe9cvMG-tFuuPtd2VZwd6paZIdG-WfT","timestamp":1594145306822}],"collapsed_sections":["M03a0Rx_G8qk","De-sVZQJYsdh","Jwyn3cHR2l7x","8ZZydFrv7rVq"],"authorship_tag":"ABX9TyM1JnvuaOrRFGYeJj06Rl2b"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JEgNgZ_YMIhS","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import gzip, shutil\n","import nibabel as nib\n","import time\n","import random\n","\n","import torch\n","from torch.utils.data import Dataset\n","\n","import torch.nn.functional as F\n","from torch import nn as nn\n","from torch.autograd import Variable\n","from torch.nn import MSELoss, SmoothL1Loss, L1Loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"th8OvOS888B8","colab_type":"code","colab":{}},"source":["nobackup = '/nobackup/sc19rw/Train/'\n","nobackup_models = '/nobackup/sc19rw/Models/'\n","home = '/home/home01/sc19rw/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M03a0Rx_G8qk","colab_type":"text"},"source":["## Data collection"]},{"cell_type":"code","metadata":{"id":"fwkeVBofs49S","colab_type":"code","colab":{}},"source":["def get_random_crop(img,cropx,cropy,cropz):\n","    x,y,z = img.shape\n","    startx = random.randint(0,(x-cropx))\n","    starty = random.randint(0,(y-cropy))\n","    startz = random.randint(0,(z-cropz))\n","    return startx, starty, startz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBLl5JlQwCVE","colab_type":"code","colab":{}},"source":["MRI_ids = np.load(home+\"MRI_ids.npz\") #make sure you use the .npz!\n","MRI_ids = MRI_ids['arr_0']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-iIj__UImW2I","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import random\n","\n","\n","root = nobackup\n","\n","data = {\n","    'image_id': MRI_ids,\n","    't1_path': [root + MRI_id + \"_t1_norm\"+ \".nii\" for MRI_id in MRI_ids],\n","    't1ce_path': [root + MRI_id + \"_t1ce_norm\" + \".nii\" for MRI_id in MRI_ids],\n","    'flair_path': [root + MRI_id + \"_flair_norm\" + \".nii\" for MRI_id in MRI_ids],\n","    't2_path': [root + MRI_id + \"_t2_norm\" + \".nii\" for MRI_id in MRI_ids],\n","    'seg_path': [root + MRI_id + \"_seg\" + \".nii\" for MRI_id in MRI_ids],\n","}\n","\n","data_df = pd.DataFrame(data, columns=['image_id', 't1_path', 't1ce_path', 'flair_path', 't2_path', 'seg_path'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePs10Qr_pAEC","colab_type":"code","colab":{}},"source":["class BRATS_DATA_CROPPED(Dataset):\n","    \"\"\" BRATS custom dataset compatible with torch.utils.data.DataLoader. \"\"\"\n","    \n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","\n","        MRI_id = self.df['image_id'][index] \n","        t1_path = self.df['t1_path'][index]\n","        t1ce_path = self.df['t1ce_path'][index]\n","        flair_path = self.df['flair_path'][index]\n","        t2_path = self.df['t2_path'][index]\n","        seg_path = self.df['seg_path'][index]\n","\n","        seg_map = nib.load(seg_path)\n","        affine = seg_map.affine\n","\n","        seg_map = seg_map.get_fdata()\n","\n","        cropx,cropy,cropz = 128, 128, 128\n","        startx,starty,startz = get_random_crop(seg_map, cropx,cropy,cropz)\n","\n","        t1_MRI = nib.load(t1_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        t1ce_MRI = nib.load(t1ce_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        flair_MRI = nib.load(flair_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        t2_MRI = nib.load(t2_path).get_fdata()[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","        seg_map = seg_map[startx:startx+cropx,starty:starty+cropy,startz:startz+cropz].reshape(1, cropx,cropy,cropz)\n","\n","        \n","        input_tensor = np.concatenate((t1_MRI, t1ce_MRI, flair_MRI, t2_MRI), axis=0) \n","     \n","\n","        return input_tensor, seg_map, affine, MRI_id\n","\n","    def __len__(self):\n","        return len(self.df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3EPRK3gbtG0i","colab_type":"code","colab":{}},"source":["class BRATS_DATA(Dataset):\n","    \"\"\" BRATS custom dataset compatible with torch.utils.data.DataLoader. \"\"\"\n","    \n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","\n","        MRI_id = self.df['image_id'][index] \n","        t1_path = self.df['t1_path'][index]\n","        t1ce_path = self.df['t1ce_path'][index]\n","        flair_path = self.df['flair_path'][index]\n","        t2_path = self.df['t2_path'][index]\n","        seg_path = self.df['seg_path'][index]\n","\n","        seg_map = nib.load(seg_path)\n","        affine = seg_map.affine\n","\n","        t1_MRI = nib.load(t1_path).get_fdata()[:].reshape(1,240,240,155)\n","        t1ce_MRI = nib.load(t1ce_path).get_fdata()[:].reshape(1,240,240,155)\n","        flair_MRI = nib.load(flair_path).get_fdata()[:].reshape(1,240,240,155)\n","        t2_MRI = nib.load(t2_path).get_fdata()[:].reshape(1,240,240,155)\n","        seg_map = seg_map.get_fdata()[:].reshape(1,240,240,155)\n","\n","        \n","        input_tensor = np.concatenate((t1_MRI, t1ce_MRI, flair_MRI, t2_MRI), axis=0) \n","     \n","\n","        return input_tensor, seg_map, affine, MRI_id\n","\n","    def __len__(self):\n","        return len(self.df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvd4iZdXxFJq","colab_type":"code","colab":{}},"source":["train_split = 0.8 # Defines the ratio of train/test data.\n","\n","train_size = round(len(data_df)*train_split)\n","test_size = round(len(data_df)*(1-train_split))\n","\n","dataset_train = BRATS_DATA_CROPPED(\n","    df=data_df[:train_size].reset_index(drop=True),\n",")\n","\n","dataset_test = BRATS_DATA_CROPPED(\n","    df=data_df[-test_size:].reset_index(drop=True),\n",")\n","\n","dataset_total = BRATS_DATA( #used to get the final segmentations\n","    df=data_df[:len(data_df)].reset_index(drop=True),\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"De-sVZQJYsdh","colab_type":"text"},"source":["##Data Augmentation"]},{"cell_type":"code","metadata":{"id":"ObGhn7nyAjyH","colab_type":"code","colab":{}},"source":["from batchgenerators.dataloading.data_loader import DataLoaderBase\n","from batchgenerators.transforms.abstract_transforms import Compose\n","from batchgenerators.dataloading.single_threaded_augmenter import SingleThreadedAugmenter\n","from batchgenerators.transforms.spatial_transforms import SpatialTransform_2\n","from batchgenerators.transforms.spatial_transforms import SpatialTransform\n","from batchgenerators.transforms.spatial_transforms import MirrorTransform\n","from batchgenerators.transforms.color_transforms import GammaTransform"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L6JRNV1GSjxf","colab_type":"code","colab":{}},"source":["class DataLoader(DataLoaderBase): #SlimDataLoaderBase \n","    def __init__(self, data, BATCH_SIZE=1, num_batches=None, seed=False):\n","        super(DataLoader, self).__init__(data, BATCH_SIZE, num_batches, seed) \n","        # data is now stored in self._data.\n","        self.index = 0\n","        self.batch_size = BATCH_SIZE\n","    \n","    def generate_train_batch(self):\n","        currentindex = self.index\n","        self.index += 1\n","        if self.index % len(self._data)  == 0:\n","          self.index = 0\n","\n","        data = self._data[self.index][0].reshape(self.batch_size, 4, 128, 128, 128)   #.numpy()\n","        seg = self._data[self.index][1].reshape(self.batch_size, 1, 128, 128, 128)\n","\n","        return {'data':data, 'seg':seg, 'affine':self._data[self.index][2], 'MRI_ID':self._data[self.index][3]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxf_Q4AZT1BT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1595937931007,"user_tz":-120,"elapsed":8724,"user":{"displayName":"Robin W","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1oQMkhoLuxB7sheDY7dP0v-uCx_Q9NOcBrD4=s64","userId":"07744434914462160854"}},"outputId":"86b24eea-a9cc-4e12-90f6-fe7cce1cb1de"},"source":["batchgen = DataLoader(dataset_train, 1, len(dataset_train), False) #Basic data loader without augmentation"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/batchgenerators/dataloading/data_loader.py:53: DeprecationWarning: This DataLoader will soon be removed. Migrate everything to SlimDataLoaderBase now!\n","  warn(\"This DataLoader will soon be removed. Migrate everything to SlimDataLoaderBase now!\", DeprecationWarning)\n","/usr/local/lib/python3.6/dist-packages/batchgenerators/dataloading/data_loader.py:58: UserWarning: We currently strongly discourage using num_batches != None! That does not seem to work properly\n","  warn(\"We currently strongly discourage using num_batches != None! That does not seem to work properly\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"SoBE6d2mjGtK","colab_type":"code","colab":{}},"source":["my_transforms = [] #define all augmentation techniques to be applied\n","\n","spatial_transform = SpatialTransform(\n","            dataset_train[0][0][0].shape, dataset_train[0][0][0].shape,\n","            do_elastic_deform=True,\n","            alpha=(0., 175.), sigma=(10., 13.),       \n","            do_rotation=True,\n","            angle_x=(- 5 / 360. * 2 * np.pi, 5 / 360. * 2 * np.pi),\n","            angle_y=(- 5 / 360. * 2 * np.pi, 5 / 360. * 2 * np.pi),\n","            angle_z=(- 5 / 360. * 2 * np.pi, 5 / 360. * 2 * np.pi),\n","            do_scale=True, scale=(0.9, 1.02),\n","            border_mode_data='constant', border_cval_data=0,\n","            border_mode_seg='constant', border_cval_seg=0,\n","            order_seg=1, order_data=3,\n","            random_crop=False,\n","            p_el_per_sample=0.1, p_rot_per_sample=0.1, p_scale_per_sample=0.1)\n","\n","\n","my_transforms.append(spatial_transform)\n","my_transforms.append(MirrorTransform(axes=(0, 1, 2)))\n","my_transforms.append(GammaTransform(gamma_range=(0.7, 1.), invert_image=False, per_channel=True, p_per_sample=0.1))\n","\n","all_transforms = Compose(my_transforms)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoFp9_AFhizK","colab_type":"code","colab":{}},"source":["train_loader = SingleThreadedAugmenter(batchgen, all_transforms) #data loader for training, applying on the fly transformation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"70xp8dPKyBfT","colab_type":"code","colab":{}},"source":["# add other data loaders\n","test_loader = torch.utils.data.DataLoader(\n","    dataset_test,\n","    batch_size=1, \n","    shuffle=False,\n","    num_workers=0,\n",")\n","\n","full_loader = torch.utils.data.DataLoader(\n","    dataset_total,\n","    batch_size=1, \n","    shuffle=False,\n","    num_workers=0,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jwyn3cHR2l7x","colab_type":"text"},"source":["## Building Model \n","\n"]},{"cell_type":"code","metadata":{"id":"5W-2KtVyL9-Q","colab_type":"code","colab":{}},"source":["class UNet(nn.Module):\n","    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n","                    torch.nn.LeakyReLU(), \n","                    torch.nn.InstanceNorm3d(out_channels), \n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm3d(out_channels),\n","                )\n","        return block\n","    \n","    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","            block = torch.nn.Sequential(\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm3d(mid_channel),\n","                    torch.nn.ConvTranspose3d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n","                    )\n","            return  block\n","    \n","    def bottleneck_block(self):\n","           block = torch.nn.Sequential(   #put this properly before\n","                            torch.nn.Conv3d(kernel_size=3, in_channels=120, out_channels=240, padding=1),\n","                            torch.nn.LeakyReLU(),\n","                            torch.nn.InstanceNorm3d(240),\n","                            torch.nn.Conv3d(kernel_size=3, in_channels=240, out_channels=120, padding=1),\n","                            torch.nn.LeakyReLU(),\n","                            torch.nn.InstanceNorm3d(120),\n","                            torch.nn.ConvTranspose3d(in_channels=120, out_channels=120, kernel_size=3, stride=2, padding=1, output_padding=1)\n","                            )\n","           return block\n","\n","    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n","            block = torch.nn.Sequential(\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm3d(mid_channel),\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm3d(mid_channel),\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n","                    #torch.nn.LeakyReLU(),\n","                    torch.nn.Sigmoid(),\n","                    )\n","            return  block\n","    \n","    def __init__(self):\n","        super(UNet, self).__init__()       \n","        #Encode\n","        self.conv_encode1 = self.contracting_block(in_channels=4, out_channels=15)\n","        self.conv_maxpool1 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode2 = self.contracting_block(15, 30)\n","        self.conv_maxpool2 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode3 = self.contracting_block(30, 60)\n","        self.conv_maxpool3 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode4 = self.contracting_block(60, 120)\n","        self.conv_maxpool4 = torch.nn.MaxPool3d(kernel_size=2)\n","        # Bottleneck\n","        self.bottleneck = self.bottleneck_block()\n","        # Decode\n","        self.conv_decode4 = self.expansive_block(240, 120, 60)\n","        self.conv_decode3 = self.expansive_block(120, 60, 30)\n","        self.conv_decode2 = self.expansive_block(60, 30, 15)\n","        self.final_layer = self.final_block(30, 15, 1)\n","        \n","    \n","    def forward(self, input_tensor):\n","        # Encode\n","        encode_block1 = self.conv_encode1(input_tensor)\n","        encode_pool1 = self.conv_maxpool1(encode_block1)\n","        encode_block2 = self.conv_encode2(encode_pool1)\n","        encode_pool2 = self.conv_maxpool2(encode_block2)\n","        encode_block3 = self.conv_encode3(encode_pool2)\n","        encode_pool3 = self.conv_maxpool3(encode_block3)\n","        encode_block4 = self.conv_encode4(encode_pool3)\n","        encode_pool4 = self.conv_maxpool4(encode_block4)\n","        # Bottleneck\n","        bottleneck1 = self.bottleneck(encode_pool4)\n","        # Decode\n","        if bottleneck1.size()[4] != encode_block4.size()[4]:\n","            bottleneck1 = F.pad(bottleneck1, pad=(1, 0), mode='constant', value=0)\n","        decode_block4 = self.conv_decode4(torch.cat((bottleneck1, encode_block4), 1))\n","        \n","        if decode_block4.size()[4] != encode_block3.size()[4]:\n","            decode_block4 = F.pad(decode_block4, pad=(1, 0), mode='constant', value=0)\n","        decode_block3 = self.conv_decode3(torch.cat((decode_block4, encode_block3), 1))\n","        \n","        if decode_block3.size()[4] != encode_block2.size()[4]:\n","            decode_block3 = F.pad(decode_block3, pad=(1, 0), mode='constant', value=0)\n","        decode_block2 = self.conv_decode2(torch.cat((decode_block3, encode_block2), 1))\n","        \n","        if decode_block2.size()[4] != encode_block1.size()[4]:\n","            decode_block2 = F.pad(decode_block2, pad=(1, 0), mode='constant', value=0)\n","        final_layer = self.final_layer(torch.cat((decode_block2, encode_block1), 1))\n","        return  final_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RkNObtdBd6Qb","colab_type":"code","colab":{}},"source":["class Discriminator(nn.Module):\n","    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n","        block = torch.nn.Sequential(\n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n","                    torch.nn.LeakyReLU(), \n","                    torch.nn.InstanceNorm3d(out_channels), \n","                    torch.nn.Conv3d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\n","                    torch.nn.LeakyReLU(),\n","                    torch.nn.InstanceNorm3d(out_channels),\n","                )\n","        return block\n","    \n","    def __init__(self):\n","        super(Discriminator, self).__init__()       \n","        self.conv_encode1 = self.contracting_block(in_channels=5, out_channels=15)\n","        self.conv_maxpool1 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode2 = self.contracting_block(15, 30)\n","        self.conv_maxpool2 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode3 = self.contracting_block(30, 60)\n","        self.conv_maxpool3 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.conv_encode4 = self.contracting_block(60, 120)\n","        self.conv_maxpool4 = torch.nn.MaxPool3d(kernel_size=2)\n","        self.final_layer1 = torch.nn.Conv3d(kernel_size=3, in_channels=120, out_channels=240, padding=1)\n","        self.final_layer2 = torch.nn.Conv3d(kernel_size=3, in_channels=240, out_channels=1, padding=1)\n","        self.final_activation = torch.nn.Sigmoid()\n","    \n","    def forward(self, input_tensor):\n","        encode_block1 = self.conv_encode1(input_tensor)\n","        encode_pool1 = self.conv_maxpool1(encode_block1)\n","        encode_block2 = self.conv_encode2(encode_pool1)\n","        encode_pool2 = self.conv_maxpool2(encode_block2)\n","        encode_block3 = self.conv_encode3(encode_pool2)\n","        encode_pool3 = self.conv_maxpool3(encode_block3)\n","        encode_block4 = self.conv_encode4(encode_pool3)\n","        encode_pool4 = self.conv_maxpool4(encode_block4)\n","        output = self.final_layer1(encode_pool4)\n","        output = self.final_layer2(output)\n","        output = self.final_activation(output)\n","\n","        return  output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JXGRiG_tJIco","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1595937933215,"user_tz":-120,"elapsed":10913,"user":{"displayName":"Robin W","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1oQMkhoLuxB7sheDY7dP0v-uCx_Q9NOcBrD4=s64","userId":"07744434914462160854"}},"outputId":"78cd9ab7-dd0b-43b1-8a05-51bd27b022b8"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"mwuzu1PuRwWi","colab_type":"code","colab":{}},"source":["class DiceLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","        \n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        #inputs = torch.sigmoid(inputs)       \n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.contiguous().view(-1)\n","        targets = targets.contiguous().view(-1)\n","        \n","        intersection = (inputs * targets).sum()                            \n","        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n","        \n","        return 1 - dice"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoF-Fd8MFEd_","colab_type":"code","colab":{}},"source":["class GeneralizedDiceLoss(nn.Module):\n","  \"\"\"\n","        Generalized Dice;\n","        Copy from: https://github.com/wolny/pytorch-3dunet/blob/6e5a24b6438f8c631289c10638a17dea14d42051/unet3d/losses.py#L75\n","        paper: https://arxiv.org/pdf/1707.03237.pdf\n","        tf code: https://github.com/NifTK/NiftyNet/blob/dev/niftynet/layer/loss_segmentation.py#L279\n","  \"\"\"\n","  def __init__(self, epsilon=1e-5, weight=None, ignore_index=None, sigmoid_normalization=True):\n","    super(GeneralizedDiceLoss, self).__init__()\n","    self.epsilon = epsilon\n","    self.register_buffer('weight', weight)\n","    self.ignore_index = ignore_index\n","    if sigmoid_normalization:\n","      self.normalization = nn.Sigmoid()\n","    else:\n","      self.normalization = nn.Softmax(dim=1)\n","\n","  def forward(self, input, target):\n","    # get probabilities from logits\n","    #input = self.normalization(input)\n","\n","    assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n","\n","    # mask ignore_index if present\n","    if self.ignore_index is not None:\n","        mask = target.clone().ne_(self.ignore_index)\n","        mask.requires_grad = False\n","\n","        input = input * mask\n","        target = target * mask\n","\n","    input = input.contiguous().view(-1)\n","    target = target.contiguous().view(-1)\n","\n","    target = target.float()\n","    target_sum = target.sum(-1)\n","    class_weights = Variable(1. / (target_sum * target_sum).clamp(min=self.epsilon), requires_grad=False)\n","\n","    intersect = (input * target).sum(-1) * class_weights\n","    if self.weight is not None:\n","        weight = Variable(self.weight, requires_grad=False)\n","        intersect = weight * intersect\n","    intersect = intersect.sum()\n","\n","    denominator = ((input + target).sum(-1) * class_weights).sum()\n","\n","    return 1. - 2. * intersect / denominator.clamp(min=self.epsilon)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nrHn0QOR2Tff","colab_type":"text"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"brefge53R4tN","colab_type":"text"},"source":["Dont forget to change model number"]},{"cell_type":"code","metadata":{"id":"8qqaVV2FR4TN","colab_type":"code","colab":{}},"source":["model_number = 'base_GAN_3D'  #CHANGE MODEL VERSION HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IhCZbzoXR8-D","colab_type":"code","colab":{}},"source":["##CHANGE HERE TO LOAD UNET MODELS##\n","LOAD_MODEL = False #HERE\n","\n","\n","with torch.no_grad(): #THIS MEANS NEED TO CREATE NEW NOTEBOOK EVERYTIME WANT TO CREATE NEW MODEL TO PRESERVE ARCHITECTURE\n","  UNet = UNet().to(device)\n","  Discriminator = Discriminator().to(device)\n","\n","optimizer_Unet = torch.optim.SGD(UNet.parameters(), lr=0.001, momentum=0.99)\n","optimizer_Dis = torch.optim.SGD(Discriminator.parameters(), lr=0.001, momentum=0.99)\n","\n","if LOAD_MODEL == True:\n","  checkpoint = torch.load(nobackup_models + model_number +'_checkpoint.pth.tar')\n","  first_epoch = checkpoint['epoch']\n","  train_dice_loss_list = checkpoint['train_dice_loss_list']\n","  test_dice_loss_list = checkpoint['test_dice_loss_list']\n","  train_loss_list = checkpoint['train_loss_list']\n","  test_loss_list = checkpoint['test_loss_list']\n","  UNet.load_state_dict(checkpoint['UNet'])\n","  Discriminator.load_state_dict(checkpoint['Dis'])\n","  optimizer_Unet.load_state_dict(checkpoint['optimizer_Unet'])\n","  optimizer_Dis.load_state_dict(checkpoint['optimizer_Dis'])\n","\n","else:\n","  first_epoch = 0\n","  train_dice_loss_list = []\n","  test_dice_loss_list = []\n","  train_loss_list = []\n","  test_loss_list = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqf3leV_UyEX","colab_type":"code","colab":{}},"source":["def save_checkpoint(state, filename=model_number):\n","    full_path = nobackup_models + filename +'_checkpoint.pth.tar'\n","    torch.save(state, full_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PPRJvcZKI9Ml","colab_type":"code","colab":{}},"source":["#criterion_Dice = DiceLoss() #try new\n","criterion_Dice = GeneralizedDiceLoss() \n","criterion_Dis = torch.nn.MSELoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8OolRbKySW3Z","colab_type":"code","colab":{}},"source":["def train_discriminator(input_tensor_axial, real_seg_axial, isreal, isfake):\n","    optimizer_Dis.zero_grad() #reset\n","    optimizer_Unet.zero_grad() \n","        \n","    fake_seg_axial = UNet(input_tensor_axial) #get predicted segmentation\n","\n","    pred_real = Discriminator(torch.cat((real_seg_axial, input_tensor_axial), 1)) #get discriminator predictions for both real and fake segmentation\n","    pred_fake = Discriminator(torch.cat((fake_seg_axial, input_tensor_axial), 1))\n","\n","    loss_real = criterion_Dis(pred_real, isreal) #get loss values for both real and fake segmentation\n","    loss_fake = criterion_Dis(pred_fake, isfake) \n","\n","    loss_Dis_element = 0.5 * (loss_real + loss_fake) #total loss for discriminator   \n","\n","    loss_Dis_element.backward() #Dis loss\n","    optimizer_Dis.step() #Optimise discriminator\n","\n","    #CLEAN UP\n","    loss_Dis_element.detach()  \n","    loss_real.detach()\n","    loss_fake.detach()\n","    del fake_seg_axial\n","    \n","def train_Unet(input_tensor_axial, real_seg_axial, isreal, isfake, lambda_val):\n","    optimizer_Unet.zero_grad() \n","    optimizer_Dis.zero_grad() \n","        \n","    fake_seg_axial = UNet(input_tensor_axial) #get predicted segmentation\n","    pred_fake = Discriminator(torch.cat((fake_seg_axial, input_tensor_axial), 1)) #Get new generator output (can be deleted and use previous)\n","\n","    loss_dice = criterion_Dice(fake_seg_axial, real_seg_axial) #Get dice loss for Unet\n","    loss_fake = criterion_Dis(pred_fake, isreal) #Get descriminator loss for Unet\n","\n","    loss_Unet_element = loss_fake + lambda_val * loss_dice #Total UNet loss\n","      \n","    loss_Unet_element.backward() \n","    \n","    optimizer_Unet.step() #Optimise Unet \n","      \n","    loss_Unet_element.detach()  \n","    loss_dice.detach()\n","    loss_fake.detach()\n","     \n","    return float(loss_dice), float(loss_Unet_element)\n","\n","def train_GAN(num_epochs, do_validation, lambda_val = 5):\n","  isreal = torch.Tensor(np.ones((8,8,8)).reshape(1, 1, 8, 8, 8)).to(device)\n","  isfake = torch.Tensor(np.zeros((8,8,8)).reshape(1, 1, 8, 8, 8)).to(device)\n","  for epoch in range(num_epochs): #train the model THIS IS TO BE USED WHEN THE ARRAYS CANNOT FIT IN MEMORY\n","    trainloss = 0\n","    testloss = 0\n","    traindiceloss = 0\n","    testdiceloss = 0\n","\n","    print(\"NEW EPOCH\")\n","    for patient, data in enumerate(train_loader): #ONLY TESTED WITH BATCH SIZE 1\n","      input_tensor_axial = torch.from_numpy(data['data']).to(device)\n","      real_seg_axial = torch.from_numpy(data['seg']).to(device)\n","      print(patient, end = ' ')\n","\n","      #TRAIN DISCRIMINATOR\n","      train_discriminator(input_tensor_axial, real_seg_axial, isreal, isfake)\n","      \n","      #TRAIN UNET   \n","      loss_dice, loss_Unet_element = train_Unet(input_tensor_axial, real_seg_axial, isreal, isfake, lambda_val)\n","\n","      traindiceloss += float(loss_dice)\n","      trainloss += float(loss_Unet_element)\n","\n","\n","    print(\"\\n Train total loss: \" + str(trainloss/(train_size)))\n","    print(\"Train Dice loss: \" + str(traindiceloss/(train_size))) \n","    train_dice_loss_list.append(traindiceloss/(train_size))\n","    train_loss_list.append(trainloss/(train_size))\n","\n","\n","    #VALIDATION \n","    if do_validation == True:\n","      with torch.no_grad():\n","        for patient, (input_tensor, seg_map, affine, MRI_ID) in enumerate(test_loader): #ONLY WORKS WITH BATCH SIZE 1\n","          input_tensor_axial = input_tensor.to(device).float() #get input slice\n","          real_seg_axial = seg_map.to(device).float() #get corresponding segmentation slice\n","        \n","          fake_seg_axial = UNet(input_tensor_axial) #get predicted segmentation\n","          pred_fake = Discriminator(torch.cat((fake_seg_axial, input_tensor_axial), 1))\n","\n","          loss_dice = criterion_Dice(fake_seg_axial, real_seg_axial)\n","          loss_fake = criterion_Dis(pred_fake, isfake)\n","\n","          loss_Unet = loss_fake + lambda_val * loss_dice\n","\n","          testloss += float(loss_Unet)\n","          testdiceloss += float(loss_dice)   \n","        print(\"Test loss: \" + str(testloss/(test_size)))\n","        print(\"Test Dice loss: \" + str(testdiceloss/(test_size))) \n","        test_dice_loss_list.append(testdiceloss/(test_size))\n","        test_loss_list.append(testloss/(test_size))\n","\n","    print(\" \")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MWpDKSL2j-7j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595947997594,"user_tz":-120,"elapsed":10075265,"user":{"displayName":"Robin W","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh1oQMkhoLuxB7sheDY7dP0v-uCx_Q9NOcBrD4=s64","userId":"07744434914462160854"}},"outputId":"189e3515-6942-4b3d-cf33-018273df2548"},"source":["num_epochs = 1\n","train_GAN(num_epochs, do_validation=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["NEW EPOCH\n","0 tensor(4.9765, grad_fn=<AddBackward0>)\n","1 tensor(4.9424, grad_fn=<AddBackward0>)\n","2 tensor(5.1804, grad_fn=<AddBackward0>)\n","3 tensor(4.1215, grad_fn=<AddBackward0>)\n","4 tensor(5.1734, grad_fn=<AddBackward0>)\n","5 tensor(5.3479, grad_fn=<AddBackward0>)\n","6 tensor(4.2657, grad_fn=<AddBackward0>)\n","7 tensor(4.4694, grad_fn=<AddBackward0>)\n","8 tensor(5.2885, grad_fn=<AddBackward0>)\n","9 tensor(4.8004, grad_fn=<AddBackward0>)\n","10 tensor(5.2671, grad_fn=<AddBackward0>)\n","11 tensor(5.3438, grad_fn=<AddBackward0>)\n","12 tensor(5.3090, grad_fn=<AddBackward0>)\n","13 tensor(5.3513, grad_fn=<AddBackward0>)\n","14 tensor(5.3762, grad_fn=<AddBackward0>)\n","15 tensor(5.1833, grad_fn=<AddBackward0>)\n","16 tensor(5.1381, grad_fn=<AddBackward0>)\n","17 tensor(5.0861, grad_fn=<AddBackward0>)\n","18 tensor(5.2546, grad_fn=<AddBackward0>)\n","19 tensor(5.4246, grad_fn=<AddBackward0>)\n","20 tensor(5.0754, grad_fn=<AddBackward0>)\n","21 tensor(4.5126, grad_fn=<AddBackward0>)\n","22 tensor(5.1059, grad_fn=<AddBackward0>)\n","23 tensor(5.6142, grad_fn=<AddBackward0>)\n","24 tensor(5.4234, grad_fn=<AddBackward0>)\n","25 tensor(5.2007, grad_fn=<AddBackward0>)\n","26 tensor(5.0159, grad_fn=<AddBackward0>)\n","27 tensor(5.2648, grad_fn=<AddBackward0>)\n","28 tensor(5.2729, grad_fn=<AddBackward0>)\n","29 tensor(4.9871, grad_fn=<AddBackward0>)\n","30 tensor(4.9815, grad_fn=<AddBackward0>)\n","31 tensor(5.0763, grad_fn=<AddBackward0>)\n","32 tensor(5.5807, grad_fn=<AddBackward0>)\n","33 tensor(5.5159, grad_fn=<AddBackward0>)\n","34 tensor(5.4348, grad_fn=<AddBackward0>)\n","35 tensor(5.3322, grad_fn=<AddBackward0>)\n","36 tensor(5.2855, grad_fn=<AddBackward0>)\n","37 tensor(5.1056, grad_fn=<AddBackward0>)\n","38 tensor(5.1927, grad_fn=<AddBackward0>)\n","39 tensor(5.1064, grad_fn=<AddBackward0>)\n","40 tensor(4.7131, grad_fn=<AddBackward0>)\n","41 tensor(5.3139, grad_fn=<AddBackward0>)\n","42 tensor(4.9782, grad_fn=<AddBackward0>)\n","43 tensor(5.2019, grad_fn=<AddBackward0>)\n","44 tensor(4.1869, grad_fn=<AddBackward0>)\n","45 tensor(5.5225, grad_fn=<AddBackward0>)\n","46 tensor(5.3545, grad_fn=<AddBackward0>)\n","47 tensor(4.3242, grad_fn=<AddBackward0>)\n","48 tensor(5.6872, grad_fn=<AddBackward0>)\n","49 tensor(5.6924, grad_fn=<AddBackward0>)\n","50 tensor(5.5638, grad_fn=<AddBackward0>)\n","51 tensor(5.7738, grad_fn=<AddBackward0>)\n","52 tensor(3.6860, grad_fn=<AddBackward0>)\n","53 tensor(5.5221, grad_fn=<AddBackward0>)\n","54 tensor(3.1060, grad_fn=<AddBackward0>)\n","55 tensor(5.3139, grad_fn=<AddBackward0>)\n","56 tensor(5.5187, grad_fn=<AddBackward0>)\n","57 tensor(5.4174, grad_fn=<AddBackward0>)\n","58 tensor(3.7224, grad_fn=<AddBackward0>)\n","59 tensor(5.3902, grad_fn=<AddBackward0>)\n","60 tensor(4.1798, grad_fn=<AddBackward0>)\n","61 tensor(5.5426, grad_fn=<AddBackward0>)\n","62 tensor(3.4167, grad_fn=<AddBackward0>)\n","63 tensor(5.5906, grad_fn=<AddBackward0>)\n","64 tensor(5.4328, grad_fn=<AddBackward0>)\n","65 tensor(5.3092, grad_fn=<AddBackward0>)\n","66 tensor(5.3865, grad_fn=<AddBackward0>)\n","67 tensor(5.1420, grad_fn=<AddBackward0>)\n","68 tensor(4.3826, grad_fn=<AddBackward0>)\n","69 tensor(5.0309, grad_fn=<AddBackward0>)\n","70 tensor(5.5029, grad_fn=<AddBackward0>)\n","71 tensor(4.2782, grad_fn=<AddBackward0>)\n","72 tensor(5.4905, grad_fn=<AddBackward0>)\n","73 tensor(2.9195, grad_fn=<AddBackward0>)\n","74 tensor(5.4156, grad_fn=<AddBackward0>)\n","75 tensor(5.5927, grad_fn=<AddBackward0>)\n","76 tensor(4.2310, grad_fn=<AddBackward0>)\n","77 tensor(3.3121, grad_fn=<AddBackward0>)\n","78 tensor(5.4767, grad_fn=<AddBackward0>)\n","79 tensor(5.3974, grad_fn=<AddBackward0>)\n","80 tensor(5.5406, grad_fn=<AddBackward0>)\n","81 tensor(5.4988, grad_fn=<AddBackward0>)\n","82 tensor(5.4401, grad_fn=<AddBackward0>)\n","83 tensor(5.5370, grad_fn=<AddBackward0>)\n","84 tensor(5.3841, grad_fn=<AddBackward0>)\n","85 tensor(5.4884, grad_fn=<AddBackward0>)\n","86 tensor(1.9969, grad_fn=<AddBackward0>)\n","87 tensor(4.5154, grad_fn=<AddBackward0>)\n","88 tensor(5.4045, grad_fn=<AddBackward0>)\n","89 tensor(2.7333, grad_fn=<AddBackward0>)\n","90 tensor(5.2772, grad_fn=<AddBackward0>)\n","91 tensor(4.7084, grad_fn=<AddBackward0>)\n","92 tensor(3.6949, grad_fn=<AddBackward0>)\n","93 tensor(5.2293, grad_fn=<AddBackward0>)\n","94 tensor(5.3775, grad_fn=<AddBackward0>)\n","95 tensor(5.1165, grad_fn=<AddBackward0>)\n","96 tensor(5.5496, grad_fn=<AddBackward0>)\n","97 tensor(5.2116, grad_fn=<AddBackward0>)\n","98 tensor(5.3871, grad_fn=<AddBackward0>)\n","99 tensor(5.2632, grad_fn=<AddBackward0>)\n","100 tensor(5.2778, grad_fn=<AddBackward0>)\n","101 tensor(5.3074, grad_fn=<AddBackward0>)\n","102 tensor(3.5302, grad_fn=<AddBackward0>)\n","103 tensor(5.4121, grad_fn=<AddBackward0>)\n","104 tensor(5.4519, grad_fn=<AddBackward0>)\n","105 tensor(3.8681, grad_fn=<AddBackward0>)\n","106 tensor(4.0363, grad_fn=<AddBackward0>)\n","107 tensor(5.4259, grad_fn=<AddBackward0>)\n","108 tensor(2.1078, grad_fn=<AddBackward0>)\n","109 tensor(5.4328, grad_fn=<AddBackward0>)\n","110 tensor(4.0396, grad_fn=<AddBackward0>)\n","111 tensor(3.9327, grad_fn=<AddBackward0>)\n","112 tensor(4.0708, grad_fn=<AddBackward0>)\n","113 tensor(5.4579, grad_fn=<AddBackward0>)\n","114 tensor(5.0308, grad_fn=<AddBackward0>)\n","115 tensor(3.5388, grad_fn=<AddBackward0>)\n","116 tensor(5.2693, grad_fn=<AddBackward0>)\n","117 tensor(5.3608, grad_fn=<AddBackward0>)\n","118 tensor(5.2508, grad_fn=<AddBackward0>)\n","119 tensor(4.8677, grad_fn=<AddBackward0>)\n","120 tensor(5.1194, grad_fn=<AddBackward0>)\n","121 tensor(5.2691, grad_fn=<AddBackward0>)\n","122 tensor(3.2556, grad_fn=<AddBackward0>)\n","123 tensor(4.9696, grad_fn=<AddBackward0>)\n","124 tensor(5.1469, grad_fn=<AddBackward0>)\n","125 tensor(4.1386, grad_fn=<AddBackward0>)\n","126 tensor(4.0462, grad_fn=<AddBackward0>)\n","127 tensor(5.2454, grad_fn=<AddBackward0>)\n","128 tensor(3.7313, grad_fn=<AddBackward0>)\n","129 tensor(5.1035, grad_fn=<AddBackward0>)\n","130 tensor(5.4152, grad_fn=<AddBackward0>)\n","131 tensor(5.2305, grad_fn=<AddBackward0>)\n","132 tensor(4.8966, grad_fn=<AddBackward0>)\n","133 tensor(4.2767, grad_fn=<AddBackward0>)\n","134 tensor(5.3196, grad_fn=<AddBackward0>)\n","135 tensor(3.6722, grad_fn=<AddBackward0>)\n","136 tensor(4.5199, grad_fn=<AddBackward0>)\n","137 tensor(5.2837, grad_fn=<AddBackward0>)\n","138 tensor(5.3661, grad_fn=<AddBackward0>)\n","139 tensor(4.8101, grad_fn=<AddBackward0>)\n","140 tensor(5.3749, grad_fn=<AddBackward0>)\n","141 tensor(5.1279, grad_fn=<AddBackward0>)\n","142 tensor(5.4375, grad_fn=<AddBackward0>)\n","143 tensor(5.2343, grad_fn=<AddBackward0>)\n","144 tensor(5.2748, grad_fn=<AddBackward0>)\n","145 tensor(5.4480, grad_fn=<AddBackward0>)\n","146 tensor(5.2674, grad_fn=<AddBackward0>)\n","147 tensor(2.1176, grad_fn=<AddBackward0>)\n","148 tensor(5.2431, grad_fn=<AddBackward0>)\n","149 tensor(5.3960, grad_fn=<AddBackward0>)\n","150 tensor(3.0426, grad_fn=<AddBackward0>)\n","151 tensor(3.2994, grad_fn=<AddBackward0>)\n","152 tensor(2.5903, grad_fn=<AddBackward0>)\n","153 tensor(2.3298, grad_fn=<AddBackward0>)\n","154 tensor(1.9155, grad_fn=<AddBackward0>)\n","155 tensor(5.2480, grad_fn=<AddBackward0>)\n","156 tensor(5.2755, grad_fn=<AddBackward0>)\n","157 tensor(4.2400, grad_fn=<AddBackward0>)\n","158 tensor(5.2168, grad_fn=<AddBackward0>)\n","159 tensor(5.4560, grad_fn=<AddBackward0>)\n","160 tensor(5.3531, grad_fn=<AddBackward0>)\n","161 tensor(5.2696, grad_fn=<AddBackward0>)\n","162 tensor(5.4971, grad_fn=<AddBackward0>)\n","163 tensor(2.3648, grad_fn=<AddBackward0>)\n","164 tensor(4.7236, grad_fn=<AddBackward0>)\n","165 tensor(5.3600, grad_fn=<AddBackward0>)\n","166 tensor(5.3143, grad_fn=<AddBackward0>)\n","167 tensor(5.3516, grad_fn=<AddBackward0>)\n","168 tensor(3.4683, grad_fn=<AddBackward0>)\n","169 tensor(5.3147, grad_fn=<AddBackward0>)\n","170 tensor(5.4189, grad_fn=<AddBackward0>)\n","171 tensor(4.4237, grad_fn=<AddBackward0>)\n","172 tensor(5.2399, grad_fn=<AddBackward0>)\n","173 tensor(4.6661, grad_fn=<AddBackward0>)\n","174 tensor(4.9629, grad_fn=<AddBackward0>)\n","175 tensor(5.3279, grad_fn=<AddBackward0>)\n","176 tensor(5.4215, grad_fn=<AddBackward0>)\n","177 tensor(5.4132, grad_fn=<AddBackward0>)\n","178 tensor(5.3431, grad_fn=<AddBackward0>)\n","179 tensor(5.4052, grad_fn=<AddBackward0>)\n","180 tensor(5.4225, grad_fn=<AddBackward0>)\n","181 tensor(4.2598, grad_fn=<AddBackward0>)\n","182 tensor(3.2884, grad_fn=<AddBackward0>)\n","183 tensor(2.2729, grad_fn=<AddBackward0>)\n","184 tensor(5.5104, grad_fn=<AddBackward0>)\n","185 tensor(4.8236, grad_fn=<AddBackward0>)\n","186 tensor(5.4136, grad_fn=<AddBackward0>)\n","187 tensor(5.1871, grad_fn=<AddBackward0>)\n","188 tensor(3.5526, grad_fn=<AddBackward0>)\n","189 tensor(5.1837, grad_fn=<AddBackward0>)\n","190 tensor(5.3440, grad_fn=<AddBackward0>)\n","191 tensor(4.0916, grad_fn=<AddBackward0>)\n","192 tensor(5.4484, grad_fn=<AddBackward0>)\n","193 tensor(3.5668, grad_fn=<AddBackward0>)\n","194 tensor(5.4886, grad_fn=<AddBackward0>)\n","195 tensor(5.4304, grad_fn=<AddBackward0>)\n","196 tensor(5.1640, grad_fn=<AddBackward0>)\n","197 tensor(5.3840, grad_fn=<AddBackward0>)\n","198 tensor(5.5901, grad_fn=<AddBackward0>)\n","199 tensor(5.6240, grad_fn=<AddBackward0>)\n","200 tensor(3.3201, grad_fn=<AddBackward0>)\n","201 tensor(5.2553, grad_fn=<AddBackward0>)\n","202 tensor(4.6865, grad_fn=<AddBackward0>)\n","203 tensor(4.0922, grad_fn=<AddBackward0>)\n","204 tensor(5.5767, grad_fn=<AddBackward0>)\n","205 tensor(4.6444, grad_fn=<AddBackward0>)\n","206 tensor(5.3488, grad_fn=<AddBackward0>)\n","207 tensor(5.4559, grad_fn=<AddBackward0>)\n","208 tensor(4.8164, grad_fn=<AddBackward0>)\n","209 tensor(5.2727, grad_fn=<AddBackward0>)\n","210 tensor(5.4976, grad_fn=<AddBackward0>)\n","211 tensor(5.4799, grad_fn=<AddBackward0>)\n","212 tensor(5.2464, grad_fn=<AddBackward0>)\n","213 tensor(5.3760, grad_fn=<AddBackward0>)\n","214 tensor(5.4552, grad_fn=<AddBackward0>)\n","215 tensor(3.6665, grad_fn=<AddBackward0>)\n","216 tensor(3.9225, grad_fn=<AddBackward0>)\n","217 tensor(5.2092, grad_fn=<AddBackward0>)\n","218 tensor(5.5840, grad_fn=<AddBackward0>)\n","219 tensor(5.2228, grad_fn=<AddBackward0>)\n","220 tensor(5.7437, grad_fn=<AddBackward0>)\n","221 tensor(5.3457, grad_fn=<AddBackward0>)\n","222 tensor(4.4067, grad_fn=<AddBackward0>)\n","223 tensor(5.6233, grad_fn=<AddBackward0>)\n","224 tensor(3.4312, grad_fn=<AddBackward0>)\n","225 tensor(2.7136, grad_fn=<AddBackward0>)\n","226 tensor(4.8347, grad_fn=<AddBackward0>)\n","227 tensor(5.0049, grad_fn=<AddBackward0>)\n","\n"," Train total loss: 4.862713194729989\n","Train Dice loss: 0.8963750203450521\n","Test loss: 0.03540608339142381\n","Test Dice loss: 0.006248648752245987\n"," \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uHnxiAFTU6VJ","colab_type":"code","colab":{}},"source":["save_checkpoint({\n","            'epoch': first_epoch+num_epochs,\n","            'UNet': UNet.state_dict(),\n","            'Dis': Discriminator.state_dict(),\n","            'train_dice_loss_list': train_dice_loss_list,\n","            'test_dice_loss_list': test_dice_loss_list,\n","            'train_loss_list': train_loss_list,\n","            'test_loss_list': test_loss_list,\n","            'optimizer_Unet' : optimizer_Unet.state_dict(),\n","            'optimizer_Dis' : optimizer_Dis.state_dict()\n","            }\n","            ) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ZZydFrv7rVq","colab_type":"text"},"source":["##Post processing"]},{"cell_type":"code","metadata":{"id":"DLHbKTYNOKhf","colab_type":"code","colab":{}},"source":["def get_short_id(long_id):\n","  short_id = \"\"\n","  for i in range(len(long_id)-5): #ignore the first 4 characters\n","    if long_id[i+4] == '/':\n","      return short_id\n","    else:\n","      short_id += long_id[i+4]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4bf08PiCEZj9","colab_type":"code","colab":{}},"source":["def save_results():\n","  newpath = nobackup_models + model_number + '_Results'\n","  if not os.path.exists(newpath):\n","    os.makedirs(newpath)\n","  with torch.no_grad():\n","    for patient, (input_tensor, seg_map, affine, MRI_ID) in enumerate(full_loader):\n","      print(patient, end = ' ')\n","      seg_3D = get_seg_wrapper(input_tensor).detach().cpu()\n","\n","      ID = get_short_id(MRI_ID[0])\n","      ni_img = nib.Nifti1Image(seg_3D.numpy(), affine.reshape(4, 4))\n","      nib.save(ni_img, newpath + '/' + ID + '.nii.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwF8PH-Ac8tp","colab_type":"code","colab":{}},"source":["def get_seg_wrapper(input_tensor):\n","  with torch.no_grad():\n","    input_tensor_axial = input_tensor.float().to(device) #change this\n","    return UNet(input_tensor_axial)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vymkcQ5rWnsK","colab_type":"code","colab":{}},"source":["finalize = False #CHANGE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0yDOr-JWwST","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"e56849bb-c250-4d5e-ff63-87d0680e8960"},"source":["if finalize == True:\n","  save_results()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 "],"name":"stdout"}]}]}